#!/usr/bin/env python3
"""
å®Œæ•´çš„èªéŸ³è½‰æ–‡å­—æ¨¡å‹æ¯”è¼ƒæ¸¬è©¦
åŸºæ–¼æ­£ç¢ºçš„ API æ–‡æª”è³‡è¨Š
"""

import os
from dotenv import load_dotenv
import time
import json
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def create_srt_from_segments(segments):
    """å¾æ®µè½è³‡è¨Šå‰µå»º SRT"""
    srt_content = []
    
    for i, segment in enumerate(segments, 1):
        start_time = format_srt_time(segment.start)
        end_time = format_srt_time(segment.end)
        text = segment.text.strip()
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)

def create_srt_from_words(words, max_chars=25, max_duration=3.0):
    """ä½¿ç”¨è©å½™ç´šæ™‚é–“æˆ³è¨˜å‰µå»ºç†æƒ³é•·åº¦çš„ SRT"""
    if not words:
        return "ç„¡è©å½™è³‡è¨Š"
    
    subtitles = []
    current_subtitle = {
        'start': None,
        'end': None,
        'text': ''
    }
    
    for word_obj in words:
        word = word_obj.word if hasattr(word_obj, 'word') else str(word_obj)
        start_time = word_obj.start if hasattr(word_obj, 'start') else 0
        end_time = word_obj.end if hasattr(word_obj, 'end') else 0
        
        word = word.strip()
        if not word:
            continue
            
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é–‹å§‹æ–°æ®µè½
        if (current_subtitle['start'] is None or 
            len(current_subtitle['text'] + word) > max_chars or
            (end_time - current_subtitle['start']) > max_duration):
            
            # ä¿å­˜ç•¶å‰æ®µè½
            if current_subtitle['text']:
                subtitles.append(current_subtitle.copy())
            
            # é–‹å§‹æ–°æ®µè½
            current_subtitle = {
                'start': start_time,
                'end': end_time,
                'text': word
            }
        else:
            # æ·»åŠ åˆ°ç•¶å‰æ®µè½
            current_subtitle['text'] += word
            current_subtitle['end'] = end_time
    
    # æ·»åŠ æœ€å¾Œä¸€å€‹æ®µè½
    if current_subtitle['text']:
        subtitles.append(current_subtitle)
    
    # ç”Ÿæˆ SRT
    srt_content = []
    for i, subtitle in enumerate(subtitles, 1):
        start_time = format_srt_time(subtitle['start'])
        end_time = format_srt_time(subtitle['end'])
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(subtitle['text'])
        srt_content.append("")
    
    return "\n".join(srt_content)

def evaluate_srt_quality(srt_content, model_name):
    """è©•ä¼° SRT å“è³ª - å°ˆæ³¨æ–¼è§£æ±ºæ®µè½éé•·å•é¡Œ"""
    print(f"\nğŸ¯ {model_name} - è§£æ±ºæ®µè½éé•·å•é¡Œè©•ä¼°")
    print("=" * 60)
    
    lines = srt_content.strip().split('\n')
    segments = []
    
    i = 0
    while i < len(lines):
        if lines[i].strip().isdigit():
            if i + 2 < len(lines):
                segment_id = int(lines[i])
                time_line = lines[i + 1]
                text_lines = []
                i += 2
                while i < len(lines) and lines[i].strip():
                    text_lines.append(lines[i])
                    i += 1
                
                if text_lines:
                    text = ' '.join(text_lines).strip()
                    segments.append({
                        'id': segment_id,
                        'time': time_line,
                        'text': text,
                        'length': len(text)
                    })
        i += 1
    
    if not segments:
        print("âŒ ç„¡æ³•è§£æ SRT å…§å®¹")
        return None
    
    lengths = [seg['length'] for seg in segments]
    
    print(f"ğŸ“Š æ®µè½é•·åº¦çµ±è¨ˆ:")
    print(f"  ç¸½æ®µè½æ•¸: {len(segments)}")
    print(f"  å¹³å‡é•·åº¦: {sum(lengths)/len(lengths):.1f} å­—ç¬¦")
    print(f"  æœ€é•·æ®µè½: {max(lengths)} å­—ç¬¦")
    print(f"  æœ€çŸ­æ®µè½: {min(lengths)} å­—ç¬¦")
    
    # æŒ‰æ‚¨çš„éœ€æ±‚åˆ†é¡æ®µè½
    perfect_length = [l for l in lengths if 15 <= l <= 30]  # ç†æƒ³å­—å¹•é•·åº¦
    acceptable_length = [l for l in lengths if 10 <= l <= 40]  # å¯æ¥å—é•·åº¦
    too_long = [l for l in lengths if l > 40]  # éé•· (æ‚¨çš„ä¸»è¦å•é¡Œ)
    too_short = [l for l in lengths if l < 10]  # éçŸ­
    
    print(f"\nğŸ¯ é‡å°æ‚¨çš„å•é¡Œåˆ†æ:")
    print(f"  ç†æƒ³é•·åº¦ (15-30å­—ç¬¦): {len(perfect_length)} å€‹ ({len(perfect_length)/len(segments)*100:.1f}%)")
    print(f"  å¯æ¥å—é•·åº¦ (10-40å­—ç¬¦): {len(acceptable_length)} å€‹ ({len(acceptable_length)/len(segments)*100:.1f}%)")
    print(f"  ğŸš¨ éé•·æ®µè½ (>40å­—ç¬¦): {len(too_long)} å€‹ ({len(too_long)/len(segments)*100:.1f}%)")
    print(f"  éçŸ­æ®µè½ (<10å­—ç¬¦): {len(too_short)} å€‹ ({len(too_short)/len(segments)*100:.1f}%)")
    
    # é¡¯ç¤ºå•é¡Œæ®µè½
    if too_long:
        print(f"\nâš ï¸ ç™¼ç¾çš„éé•·æ®µè½ (>40å­—ç¬¦):")
        for seg in segments:
            if seg['length'] > 40:
                print(f"  æ®µè½ {seg['id']}: {seg['length']} å­—ç¬¦")
                print(f"    æ™‚é–“: {seg['time']}")
                print(f"    å…§å®¹: {seg['text']}")
                print()
    
    # å•é¡Œè§£æ±ºæ•ˆæœè©•åˆ†
    problem_solving_score = 0
    
    # ä¸»è¦æŒ‡æ¨™ï¼šæ²’æœ‰éé•·æ®µè½ (50%)
    if len(too_long) == 0:
        problem_solving_score += 50
    elif len(too_long) <= 2:
        problem_solving_score += 30
    elif len(too_long) <= 5:
        problem_solving_score += 10
    
    # ç†æƒ³æ®µè½æ¯”ä¾‹ (30%)
    problem_solving_score += (len(perfect_length) / len(segments)) * 30
    
    # å¯æ¥å—æ®µè½æ¯”ä¾‹ (20%)
    problem_solving_score += (len(acceptable_length) / len(segments)) * 20
    
    print(f"\nğŸ“ˆ å•é¡Œè§£æ±ºæ•ˆæœè©•åˆ†: {problem_solving_score:.1f}/100")
    
    if problem_solving_score >= 80:
        rating = "ğŸ† å„ªç§€ - å®Œç¾è§£æ±ºæ‚¨çš„å•é¡Œ"
    elif problem_solving_score >= 60:
        rating = "âœ… è‰¯å¥½ - å¤§å¹…æ”¹å–„æ‚¨çš„å•é¡Œ"
    elif problem_solving_score >= 40:
        rating = "âš ï¸ ä¸€èˆ¬ - éƒ¨åˆ†è§£æ±ºæ‚¨çš„å•é¡Œ"
    else:
        rating = "âŒ ä¸ä½³ - æœªèƒ½è§£æ±ºæ‚¨çš„å•é¡Œ"
    
    print(f"ğŸ¯ æ•´é«”è©•ç´š: {rating}")
    
    return {
        'total_segments': len(segments),
        'avg_length': sum(lengths)/len(lengths),
        'max_length': max(lengths),
        'perfect_count': len(perfect_length),
        'acceptable_count': len(acceptable_length),
        'too_long_count': len(too_long),
        'too_short_count': len(too_short),
        'problem_solving_score': problem_solving_score,
        'rating': rating
    }

def test_model_comprehensive(client, model, audio_file, provider="OpenAI"):
    """å…¨é¢æ¸¬è©¦å–®å€‹æ¨¡å‹çš„æ‰€æœ‰èƒ½åŠ›"""
    print(f"\nğŸš€ å…¨é¢æ¸¬è©¦ {provider} {model}")
    print("=" * 60)
    
    results = []
    
    # é‡å°æ‚¨çš„å•é¡Œè¨­è¨ˆçš„å°ˆæ¥­ Prompt
    optimized_prompt = """é€™æ˜¯è²¡ç¶“æ–°èå…§å®¹ã€‚è«‹è½‰éŒ„ä¸¦å„ªåŒ–ç‚ºå­—å¹•æ ¼å¼ï¼š
- æ¯æ®µè½ 15-30 å­—ç¬¦
- åœ¨è‡ªç„¶åœé “è™•åˆ†æ®µ
- ä¿æŒèªç¾©å®Œæ•´
- æ­£ç¢ºè­˜åˆ¥ï¼šå°ç©é›»ã€è¯é›»ã€æ—¥æœˆå…‰ã€NVIDIAã€ADRã€é‚£æ–¯é”å…‹ã€è²»åŠã€æ¯”ç‰¹å¹£
- ä½¿ç”¨ç¹é«”ä¸­æ–‡
- é©ç•¶æ¨™é»ç¬¦è™Ÿ"""
    
    # æ¸¬è©¦é…ç½®
    test_configs = []
    
    if "gpt-4o" in model:
        # 4o æ¨¡å‹çš„æ­£ç¢ºæ¸¬è©¦æ–¹æ³•
        test_configs = [
            ("JSONåŸºæœ¬", "json", None, None),
            ("JSON+æ®µè½æ™‚é–“æˆ³è¨˜", "json", ["segment"], None),
            ("JSON+è©å½™æ™‚é–“æˆ³è¨˜", "json", ["word"], None), 
            ("JSON+å…¨æ™‚é–“æˆ³è¨˜", "json", ["segment", "word"], None),
            ("JSON+å°ˆæ¥­Prompt", "json", ["segment", "word"], optimized_prompt)
        ]
    elif model == "whisper-1":
        # Whisper-1 çš„æ¸¬è©¦æ–¹æ³•
        test_configs = [
            ("åŸºæº–SRT", "srt", None, None),
            ("è©³ç´°JSON", "verbose_json", ["segment", "word"], None),
            ("å°ˆæ¥­Prompt+SRT", "srt", None, optimized_prompt),
            ("å°ˆæ¥­Prompt+è©³ç´°JSON", "verbose_json", ["segment", "word"], optimized_prompt)
        ]
    elif "whisper-large-v3" in model:
        # Groq Whisper Large v3 çš„æ¸¬è©¦æ–¹æ³•
        test_configs = [
            ("åŸºæº–", "verbose_json", None, None),
            ("å°ˆæ¥­Prompt", "verbose_json", None, optimized_prompt)
        ]
    
    for config_name, response_format, timestamp_granularities, prompt in test_configs:
        print(f"\n--- é…ç½®: {config_name} ---")
        
        try:
            start_time = time.time()
            
            # æ§‹å»º API åƒæ•¸
            params = {
                "model": model,
                "file": open(audio_file, "rb"),
                "response_format": response_format,
                "language": "zh"
            }
            
            if prompt:
                params["prompt"] = prompt
                print(f"ğŸ“ ä½¿ç”¨å°ˆæ¥­ Prompt")
            
            if timestamp_granularities:
                params["timestamp_granularities"] = timestamp_granularities
                print(f"â±ï¸ æ™‚é–“æˆ³è¨˜ç²’åº¦: {timestamp_granularities}")
            
            transcription = client.audio.transcriptions.create(**params)
            
            processing_time = time.time() - start_time
            
            print(f"âœ… æˆåŠŸ - è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
            
            # æª¢æŸ¥çµæœé¡å‹
            print(f"ğŸ“Š å›æ‡‰é¡å‹: {type(transcription).__name__}")
            
            # ç²å–æ–‡å­—
            if hasattr(transcription, 'text'):
                text = transcription.text
                print(f"ğŸ“ æ–‡å­—é•·åº¦: {len(text)} å­—ç¬¦")
            else:
                text = str(transcription)
                print(f"ğŸ“ å…§å®¹é•·åº¦: {len(text)} å­—ç¬¦")
            
            # æª¢æŸ¥æ™‚é–“æˆ³è¨˜æ”¯æ´
            has_segments = hasattr(transcription, 'segments') and transcription.segments
            has_words = hasattr(transcription, 'words') and transcription.words
            
            segment_count = len(transcription.segments) if has_segments else 0
            word_count = len(transcription.words) if has_words else 0
            
            print(f"ğŸ“Š æ®µè½ç´šæ™‚é–“æˆ³è¨˜: {'âœ…' if has_segments else 'âŒ'} ({segment_count} å€‹)")
            print(f"ğŸ“ è©å½™ç´šæ™‚é–“æˆ³è¨˜: {'âœ…' if has_words else 'âŒ'} ({word_count} å€‹)")
            
            # å‰µå»º SRT
            srt_content = None
            srt_analysis = None
            
            if response_format == "srt":
                srt_content = text
            elif has_segments:
                srt_content = create_srt_from_segments(transcription.segments)
            elif has_words:
                srt_content = create_srt_from_words(transcription.words)
            
            if srt_content:
                # ä¿å­˜ SRT
                filename = f"{provider.lower()}_{model.replace('-', '_').replace('/', '_')}_{config_name.replace(' ', '_').replace('+', '_')}.srt"
                with open(filename, "w", encoding="utf-8") as f:
                    f.write(srt_content)
                print(f"ğŸ’¾ SRT å·²ä¿å­˜: {filename}")
                
                # è©•ä¼° SRT å“è³ª
                srt_analysis = evaluate_srt_quality(srt_content, f"{provider} {model} {config_name}")
            
            # é¡¯ç¤ºæ–‡å­—å“è³ªé è¦½
            print(f"ğŸ“– è½‰éŒ„å“è³ªé è¦½:")
            print(f"  {text[:200]}...")
            
            results.append({
                'provider': provider,
                'model': model,
                'config': config_name,
                'response_format': response_format,
                'timestamp_granularities': timestamp_granularities,
                'prompt': prompt is not None,
                'success': True,
                'processing_time': processing_time,
                'text': text,
                'has_segments': has_segments,
                'has_words': has_words,
                'segment_count': segment_count,
                'word_count': word_count,
                'srt_content': srt_content,
                'srt_analysis': srt_analysis
            })
            
        except Exception as e:
            print(f"âŒ å¤±æ•— - éŒ¯èª¤: {str(e)}")
            results.append({
                'provider': provider,
                'model': model,
                'config': config_name,
                'success': False,
                'error': str(e)
            })
        
        time.sleep(1)
    
    return results

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸ - æ‰¾åˆ°æ¯” Whisper-1 æ›´å¥½çš„æ¨¡å‹"""
    print("ğŸ¯ å®Œæ•´èªéŸ³è½‰æ–‡å­—æ¨¡å‹æ¯”è¼ƒ - å°‹æ‰¾æ¯” Whisper-1 æ›´å¥½çš„è§£æ±ºæ–¹æ¡ˆ")
    print("=" * 80)
    
    # API è¨­å®š
    openai_api_key = os.getenv("OPENAI_API_KEY")
    groq_api_key = os.getenv("GROQ_API_KEY")
    
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” {audio_file}")
        return
    
    all_results = []
    
    # 1. æ¸¬è©¦ OpenAI whisper-1 (åŸºæº–)
    print(f"\nğŸ“Š ç¬¬ä¸€éƒ¨åˆ†ï¼šOpenAI Whisper-1 (åŸºæº–æ¨¡å‹)")
    openai_client = OpenAI(api_key=openai_api_key)
    whisper1_results = test_model_comprehensive(openai_client, "whisper-1", audio_file, "OpenAI")
    all_results.extend(whisper1_results)
    
    # 2. æ¸¬è©¦ OpenAI æ–°æ¨¡å‹ (æ­£ç¢ºæ–¹æ³•)
    print(f"\nğŸ“Š ç¬¬äºŒéƒ¨åˆ†ï¼šOpenAI æ–°ä¸€ä»£æ¨¡å‹ (æ­£ç¢ºæ¸¬è©¦)")
    for model in ["gpt-4o-transcribe", "gpt-4o-mini-transcribe"]:
        model_results = test_model_comprehensive(openai_client, model, audio_file, "OpenAI")
        all_results.extend(model_results)
    
    # 3. æ¸¬è©¦ Groq Whisper Large v3
    print(f"\nğŸ“Š ç¬¬ä¸‰éƒ¨åˆ†ï¼šGroq Whisper Large v3")
    groq_client = OpenAI(
        api_key=groq_api_key,
        base_url="https://api.groq.com/openai/v1"
    )
    groq_results = test_model_comprehensive(groq_client, "whisper-large-v3", audio_file, "Groq")
    all_results.extend(groq_results)
    
    # 4. åˆ†æå’Œæ’å
    print(f"\n" + "=" * 80)
    print(f"ğŸ† å°‹æ‰¾æ¯” Whisper-1 æ›´å¥½çš„è§£æ±ºæ–¹æ¡ˆ")
    print("=" * 80)
    
    # ç²å–æ‰€æœ‰æˆåŠŸä¸”æœ‰ SRT çš„çµæœ
    srt_results = [r for r in all_results if r['success'] and r.get('srt_analysis')]
    
    if srt_results:
        # æŒ‰å•é¡Œè§£æ±ºæ•ˆæœæ’åº
        srt_results.sort(key=lambda x: x['srt_analysis']['problem_solving_score'], reverse=True)
        
        print(f"ğŸ“ˆ è§£æ±ºæ‚¨å•é¡Œçš„æ•ˆæœæ’è¡Œæ¦œ:")
        
        whisper1_baseline = None
        
        for i, result in enumerate(srt_results, 1):
            analysis = result['srt_analysis']
            model_info = f"{result['provider']} {result['model']} ({result['config']})"
            
            # è¨˜éŒ„ whisper-1 åŸºæº–
            if result['model'] == 'whisper-1' and 'baseline' in result['config'].lower():
                whisper1_baseline = analysis
            
            print(f"  {i}. {model_info}")
            print(f"     å•é¡Œè§£æ±ºåº¦: {analysis['problem_solving_score']:.1f}/100")
            print(f"     éé•·æ®µè½: {analysis['too_long_count']} å€‹")
            print(f"     ç†æƒ³æ®µè½: {analysis['perfect_count']} å€‹ ({analysis['perfect_count']/analysis['total_segments']*100:.1f}%)")
            print(f"     è™•ç†é€Ÿåº¦: {result['processing_time']:.2f} ç§’")
            print(f"     æ•´é«”è©•ç´š: {analysis['rating']}")
            
            # èˆ‡ whisper-1 æ¯”è¼ƒ
            if whisper1_baseline and result['model'] != 'whisper-1':
                improvement = analysis['problem_solving_score'] - whisper1_baseline['problem_solving_score']
                if improvement > 10:
                    print(f"     ğŸ‰ æ¯” Whisper-1 æ”¹å–„ {improvement:.1f} åˆ†ï¼")
                elif improvement > 0:
                    print(f"     âœ… æ¯” Whisper-1 ç•¥æœ‰æ”¹å–„ (+{improvement:.1f} åˆ†)")
                else:
                    print(f"     âŒ ä¸å¦‚ Whisper-1 ({improvement:.1f} åˆ†)")
            
            print()
        
        # æ‰¾å‡ºæœ€ä½³è§£æ±ºæ–¹æ¡ˆ
        best_solution = srt_results[0]
        print(f"ğŸ… æœ€ä½³è§£æ±ºæ–¹æ¡ˆ: {best_solution['provider']} {best_solution['model']} ({best_solution['config']})")
        print(f"   å•é¡Œè§£æ±ºåº¦: {best_solution['srt_analysis']['problem_solving_score']:.1f}/100")
        print(f"   {best_solution['srt_analysis']['rating']}")
        
        # é€Ÿåº¦å† è»
        fastest = min(srt_results, key=lambda x: x['processing_time'])
        print(f"\nâš¡ é€Ÿåº¦å† è»: {fastest['provider']} {fastest['model']} - {fastest['processing_time']:.2f} ç§’")
    
    # 5. æ™‚é–“æˆ³è¨˜æ”¯æ´ç¸½çµ
    print(f"\nğŸ“Š æ™‚é–“æˆ³è¨˜æ”¯æ´ç¸½çµ:")
    
    models_with_segments = [r for r in all_results if r['success'] and r['has_segments']]
    models_with_words = [r for r in all_results if r['success'] and r['has_words']]
    
    print(f"æ”¯æ´æ®µè½ç´šæ™‚é–“æˆ³è¨˜:")
    for result in models_with_segments:
        print(f"  âœ… {result['provider']} {result['model']} ({result['segment_count']} æ®µè½)")
    
    print(f"æ”¯æ´è©å½™ç´šæ™‚é–“æˆ³è¨˜:")
    for result in models_with_words:
        print(f"  âœ… {result['provider']} {result['model']} ({result['word_count']} è©å½™)")
    
    # 6. ä¿å­˜å®Œæ•´çµæœ
    with open("complete_model_comparison_results.json", "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ’¾ å®Œæ•´æ¯”è¼ƒçµæœå·²ä¿å­˜åˆ°: complete_model_comparison_results.json")
    print("ğŸ‰ å®Œæ•´æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()
