#!/usr/bin/env python3
"""
æ­£ç¢ºæ¸¬è©¦ OpenAI 4o æ¨¡å‹çš„æ™‚é–“æˆ³è¨˜æ”¯æ´
æ ¹æ“šæœ€æ–°æ–‡æª”ï¼Œ4o æ¨¡å‹ç¢ºå¯¦æ”¯æ´ timestamp_granularities
"""

import os
from dotenv import load_dotenv
import time
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def test_4o_models_correct():
    """æ­£ç¢ºæ¸¬è©¦ 4o æ¨¡å‹"""
    
    api_key = os.getenv("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)
    
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” {audio_file}")
        return
    
    print("ğŸ” æ­£ç¢ºæ¸¬è©¦ OpenAI 4o æ¨¡å‹çš„æ™‚é–“æˆ³è¨˜æ”¯æ´")
    print("=" * 60)
    
    # æ ¹æ“šæœå°‹çµæœï¼Œ4o æ¨¡å‹ç¢ºå¯¦æ”¯æ´ timestamp_granularities
    test_cases = [
        {
            "model": "gpt-4o-transcribe",
            "response_format": "json",
            "timestamp_granularities": ["segment"],
            "description": "4o-transcribe JSON + æ®µè½æ™‚é–“æˆ³è¨˜"
        },
        {
            "model": "gpt-4o-transcribe",
            "response_format": "json", 
            "timestamp_granularities": ["word"],
            "description": "4o-transcribe JSON + è©å½™æ™‚é–“æˆ³è¨˜"
        },
        {
            "model": "gpt-4o-transcribe",
            "response_format": "json",
            "timestamp_granularities": ["segment", "word"],
            "description": "4o-transcribe JSON + æ®µè½+è©å½™æ™‚é–“æˆ³è¨˜"
        },
        {
            "model": "gpt-4o-mini-transcribe",
            "response_format": "json",
            "timestamp_granularities": ["segment"],
            "description": "4o-mini JSON + æ®µè½æ™‚é–“æˆ³è¨˜"
        },
        {
            "model": "gpt-4o-mini-transcribe",
            "response_format": "json",
            "timestamp_granularities": ["word"],
            "description": "4o-mini JSON + è©å½™æ™‚é–“æˆ³è¨˜"
        }
    ]
    
    results = []
    
    for test_case in test_cases:
        print(f"\n--- {test_case['description']} ---")
        
        try:
            start_time = time.time()
            
            with open(audio_file, "rb") as f:
                transcription = client.audio.transcriptions.create(
                    model=test_case["model"],
                    file=f,
                    response_format=test_case["response_format"],
                    timestamp_granularities=test_case["timestamp_granularities"],
                    language="zh"
                )
            
            processing_time = time.time() - start_time
            
            print(f"âœ… æˆåŠŸ - è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
            
            # æª¢æŸ¥å›æ‡‰çµæ§‹
            print(f"ğŸ“Š å›æ‡‰é¡å‹: {type(transcription)}")
            
            if hasattr(transcription, '__dict__'):
                print(f"ğŸ“‹ ç‰©ä»¶å±¬æ€§:")
                for attr, value in transcription.__dict__.items():
                    if attr == 'text':
                        print(f"  {attr}: {len(str(value))} å­—ç¬¦")
                    elif attr in ['segments', 'words']:
                        if value:
                            print(f"  {attr}: {len(value)} å€‹")
                        else:
                            print(f"  {attr}: None")
                    else:
                        print(f"  {attr}: {str(value)[:50]}...")
            
            # æª¢æŸ¥æ™‚é–“æˆ³è¨˜
            has_segments = hasattr(transcription, 'segments') and transcription.segments
            has_words = hasattr(transcription, 'words') and transcription.words
            
            if has_segments:
                print(f"ğŸ‰ ç™¼ç¾æ®µè½ç´šæ™‚é–“æˆ³è¨˜: {len(transcription.segments)} å€‹æ®µè½")
                first_seg = transcription.segments[0]
                print(f"   ç¬¬ä¸€æ®µ: [{first_seg.start:.2f}-{first_seg.end:.2f}] {first_seg.text}")
            
            if has_words:
                print(f"ğŸ‰ ç™¼ç¾è©å½™ç´šæ™‚é–“æˆ³è¨˜: {len(transcription.words)} å€‹è©å½™")
                for i, word in enumerate(transcription.words[:3]):
                    print(f"   è©å½™ {i+1}: [{word.start:.2f}-{word.end:.2f}] '{word.word}'")
            
            if not has_segments and not has_words:
                print(f"âŒ æ²’æœ‰ç™¼ç¾ä»»ä½•æ™‚é–“æˆ³è¨˜")
            
            results.append({
                'model': test_case['model'],
                'description': test_case['description'],
                'success': True,
                'processing_time': processing_time,
                'has_segments': has_segments,
                'has_words': has_words,
                'segment_count': len(transcription.segments) if has_segments else 0,
                'word_count': len(transcription.words) if has_words else 0
            })
            
        except Exception as e:
            print(f"âŒ å¤±æ•— - éŒ¯èª¤: {str(e)}")
            results.append({
                'model': test_case['model'],
                'description': test_case['description'],
                'success': False,
                'error': str(e)
            })
        
        time.sleep(1)
    
    # ç¸½çµ
    print(f"\n" + "=" * 60)
    print(f"ğŸ“Š 4o æ¨¡å‹æ™‚é–“æˆ³è¨˜æ”¯æ´æœ€çµ‚çµè«–")
    print("=" * 60)
    
    successful = [r for r in results if r['success']]
    with_timestamps = [r for r in successful if r['has_segments'] or r['has_words']]
    
    if with_timestamps:
        print(f"ğŸ‰ ç¢ºèªï¼4o æ¨¡å‹æ”¯æ´æ™‚é–“æˆ³è¨˜:")
        for result in with_timestamps:
            print(f"  âœ… {result['description']}")
            print(f"     æ®µè½ç´š: {'âœ…' if result['has_segments'] else 'âŒ'} ({result['segment_count']})")
            print(f"     è©å½™ç´š: {'âœ…' if result['has_words'] else 'âŒ'} ({result['word_count']})")
    else:
        print(f"âŒ ç¢ºèªï¼š4o æ¨¡å‹ä¸æ”¯æ´æ™‚é–“æˆ³è¨˜")
        print(f"   æ‰€æœ‰æ¸¬è©¦éƒ½æ²’æœ‰è¿”å›æ™‚é–“æˆ³è¨˜è³‡è¨Š")
    
    return results

if __name__ == "__main__":
    test_4o_models_correct()
