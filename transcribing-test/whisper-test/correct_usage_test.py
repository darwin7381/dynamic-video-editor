#!/usr/bin/env python3
"""
åŸºæ–¼æ­£ç¢ºç”¨æ³•çš„ OpenAI èªéŸ³è½‰æ–‡å­—æ¨¡å‹æ¸¬è©¦
æ ¹æ“šå¯¦éš›æ¸¬è©¦çµæœåˆ¶å®šçš„æ­£ç¢ºä½¿ç”¨æ–¹æ³•
"""

import os
from dotenv import load_dotenv
import time
import json
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def create_custom_srt_from_words(words, max_chars=40, max_duration=3.0):
    """ä½¿ç”¨è©å½™ç´šæ™‚é–“æˆ³è¨˜å‰µå»ºè‡ªå®šç¾© SRT - é€™æ˜¯è§£æ±ºæ®µè½éé•·çš„é—œéµï¼"""
    if not words:
        return "ç„¡è©å½™è³‡è¨Šå¯ç”¨"
    
    subtitles = []
    current_subtitle = {
        'start': None,
        'end': None,
        'text': ''
    }
    
    for word_obj in words:
        word = word_obj.word if hasattr(word_obj, 'word') else str(word_obj)
        start_time = word_obj.start if hasattr(word_obj, 'start') else 0
        end_time = word_obj.end if hasattr(word_obj, 'end') else 0
        
        # æ¸…ç†è©å½™ï¼ˆå»é™¤å‰å¾Œç©ºæ ¼ï¼‰
        word = word.strip()
        if not word:
            continue
            
        # å¦‚æœæ˜¯ç¬¬ä¸€å€‹è©æˆ–éœ€è¦é–‹å§‹æ–°æ®µè½
        if (current_subtitle['start'] is None or 
            len(current_subtitle['text'] + word) > max_chars or
            (end_time - current_subtitle['start']) > max_duration):
            
            # ä¿å­˜ç•¶å‰å­—å¹•æ®µè½
            if current_subtitle['text']:
                subtitles.append(current_subtitle.copy())
            
            # é–‹å§‹æ–°æ®µè½
            current_subtitle = {
                'start': start_time,
                'end': end_time,
                'text': word
            }
        else:
            # æ·»åŠ åˆ°ç•¶å‰æ®µè½
            current_subtitle['text'] += word
            current_subtitle['end'] = end_time
    
    # æ·»åŠ æœ€å¾Œä¸€å€‹æ®µè½
    if current_subtitle['text']:
        subtitles.append(current_subtitle)
    
    return generate_srt_content(subtitles)

def generate_srt_content(subtitles):
    """ç”Ÿæˆæ¨™æº– SRT æ ¼å¼å…§å®¹"""
    srt_content = []
    
    for i, subtitle in enumerate(subtitles, 1):
        start_time = format_srt_time(subtitle['start'])
        end_time = format_srt_time(subtitle['end'])
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(subtitle['text'])
        srt_content.append("")  # ç©ºè¡Œ
    
    return "\n".join(srt_content)

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def analyze_srt_quality(srt_content):
    """åˆ†æ SRT å“è³ª"""
    lines = srt_content.strip().split('\n')
    segments = []
    current_text = ""
    
    for line in lines:
        if line.strip().isdigit():
            if current_text:
                segments.append(current_text.strip())
            current_text = ""
        elif "-->" not in line and line.strip():
            current_text += line + " "
    
    if current_text:
        segments.append(current_text.strip())
    
    if segments:
        segment_lengths = [len(seg) for seg in segments]
        return {
            'segment_count': len(segments),
            'avg_length': sum(segment_lengths) / len(segment_lengths),
            'max_length': max(segment_lengths),
            'min_length': min(segment_lengths)
        }
    return None

def main():
    api_key = os.getenv("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)
    
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print("éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” test_audio.mp3")
        return
    
    print("ğŸ¯ æ­£ç¢ºç”¨æ³•æ¸¬è©¦ - è§£æ±º SRT æ®µè½éé•·å•é¡Œ")
    print("="*60)
    
    results = []
    
    # 1. æ¸¬è©¦ Whisper-1 åŸå§‹ SRT
    print("\nğŸ“Š ç¬¬ä¸€éƒ¨åˆ†ï¼šWhisper-1 åŸå§‹ SRT æ¸¬è©¦")
    print("-" * 40)
    
    try:
        start_time = time.time()
        
        with open(audio_file, "rb") as f:
            original_srt = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="srt",
                language="zh"
            )
        
        processing_time = time.time() - start_time
        
        print(f"âœ… åŸå§‹ SRT ç”ŸæˆæˆåŠŸ - è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
        
        # åˆ†æåŸå§‹ SRT å“è³ª
        original_quality = analyze_srt_quality(original_srt)
        print(f"åŸå§‹ SRT å“è³ª:")
        print(f"  æ®µè½æ•¸: {original_quality['segment_count']}")
        print(f"  å¹³å‡é•·åº¦: {original_quality['avg_length']:.1f} å­—ç¬¦")
        print(f"  æœ€é•·æ®µè½: {original_quality['max_length']} å­—ç¬¦")
        print(f"  æœ€çŸ­æ®µè½: {original_quality['min_length']} å­—ç¬¦")
        
        # ä¿å­˜åŸå§‹ SRT
        with open("original_srt.srt", "w", encoding="utf-8") as f:
            f.write(original_srt)
        print("åŸå§‹ SRT å·²ä¿å­˜: original_srt.srt")
        
        results.append({
            'method': 'whisper-1_original_srt',
            'processing_time': processing_time,
            'quality': original_quality,
            'success': True
        })
        
    except Exception as e:
        print(f"âŒ åŸå§‹ SRT æ¸¬è©¦å¤±æ•—: {str(e)}")
        results.append({
            'method': 'whisper-1_original_srt',
            'success': False,
            'error': str(e)
        })
    
    # 2. æ¸¬è©¦ Whisper-1 è©å½™ç´šæ™‚é–“æˆ³è¨˜ + è‡ªå®šç¾© SRT
    print(f"\nğŸš€ ç¬¬äºŒéƒ¨åˆ†ï¼šWhisper-1 è©å½™ç´šæ™‚é–“æˆ³è¨˜ + è‡ªå®šç¾© SRT")
    print("-" * 40)
    
    try:
        start_time = time.time()
        
        with open(audio_file, "rb") as f:
            verbose_response = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],  # é—œéµï¼åŒæ™‚ç²å¾—æ®µè½å’Œè©å½™ç´šæ™‚é–“æˆ³è¨˜
                language="zh"
            )
        
        processing_time = time.time() - start_time
        
        print(f"âœ… è©å½™ç´šæ™‚é–“æˆ³è¨˜ç²å–æˆåŠŸ - è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
        print(f"æ®µè½æ•¸: {len(verbose_response.segments) if hasattr(verbose_response, 'segments') else 0}")
        print(f"è©å½™æ•¸: {len(verbose_response.words) if hasattr(verbose_response, 'words') else 0}")
        
        # ä½¿ç”¨è©å½™ç´šæ™‚é–“æˆ³è¨˜å‰µå»ºè‡ªå®šç¾© SRT
        if hasattr(verbose_response, 'words') and verbose_response.words:
            print("\nå‰µå»ºè‡ªå®šç¾© SRT (æœ€å¤§ 40 å­—ç¬¦/æ®µè½, æœ€å¤§ 3 ç§’/æ®µè½)...")
            
            custom_srt = create_custom_srt_from_words(
                verbose_response.words,
                max_chars=40,
                max_duration=3.0
            )
            
            # åˆ†æè‡ªå®šç¾© SRT å“è³ª
            custom_quality = analyze_srt_quality(custom_srt)
            print(f"è‡ªå®šç¾© SRT å“è³ª:")
            print(f"  æ®µè½æ•¸: {custom_quality['segment_count']}")
            print(f"  å¹³å‡é•·åº¦: {custom_quality['avg_length']:.1f} å­—ç¬¦")
            print(f"  æœ€é•·æ®µè½: {custom_quality['max_length']} å­—ç¬¦")
            print(f"  æœ€çŸ­æ®µè½: {custom_quality['min_length']} å­—ç¬¦")
            
            # ä¿å­˜è‡ªå®šç¾© SRT
            with open("custom_word_level_srt.srt", "w", encoding="utf-8") as f:
                f.write(custom_srt)
            print("è‡ªå®šç¾© SRT å·²ä¿å­˜: custom_word_level_srt.srt")
            
            results.append({
                'method': 'whisper-1_word_level_custom',
                'processing_time': processing_time,
                'quality': custom_quality,
                'success': True
            })
            
        else:
            print("âŒ æ²’æœ‰è©å½™ç´šæ™‚é–“æˆ³è¨˜è³‡è¨Š")
            results.append({
                'method': 'whisper-1_word_level_custom',
                'success': False,
                'error': 'æ²’æœ‰è©å½™ç´šæ™‚é–“æˆ³è¨˜'
            })
            
    except Exception as e:
        print(f"âŒ è©å½™ç´šæ™‚é–“æˆ³è¨˜æ¸¬è©¦å¤±æ•—: {str(e)}")
        results.append({
            'method': 'whisper-1_word_level_custom',
            'success': False,
            'error': str(e)
        })
    
    # 3. æ¸¬è©¦æ–°æ¨¡å‹ï¼ˆåƒ…æ”¯æ´ JSON/TEXT æ ¼å¼ï¼‰
    print(f"\nâ­ ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ–°æ¨¡å‹æ¸¬è©¦ (gpt-4o-transcribe & gpt-4o-mini-transcribe)")
    print("-" * 40)
    
    new_models = [
        ("gpt-4o-transcribe", "æœ€æ–°æ——è‰¦æ¨¡å‹"),
        ("gpt-4o-mini-transcribe", "å¿«é€Ÿç‰ˆæœ¬")
    ]
    
    for model, description in new_models:
        print(f"\næ¸¬è©¦ {model} ({description})...")
        
        try:
            start_time = time.time()
            
            with open(audio_file, "rb") as f:
                transcription = client.audio.transcriptions.create(
                    model=model,
                    file=f,
                    response_format="json",  # æ–°æ¨¡å‹åªæ”¯æ´ json å’Œ text
                    language="zh"
                )
            
            processing_time = time.time() - start_time
            
            text = transcription.text if hasattr(transcription, 'text') else str(transcription)
            
            print(f"âœ… {model} æˆåŠŸ - è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
            print(f"æ–‡å­—é•·åº¦: {len(text)} å­—ç¬¦")
            print("æ–‡å­—é è¦½:")
            print(text[:200] + "..." if len(text) > 200 else text)
            
            # ä¿å­˜è½‰éŒ„çµæœ
            filename = f"{model.replace('-', '_')}_transcription.txt"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(text)
            print(f"è½‰éŒ„çµæœå·²ä¿å­˜: {filename}")
            
            results.append({
                'method': model,
                'processing_time': processing_time,
                'text_length': len(text),
                'success': True
            })
            
        except Exception as e:
            print(f"âŒ {model} æ¸¬è©¦å¤±æ•—: {str(e)}")
            results.append({
                'method': model,
                'success': False,
                'error': str(e)
            })
        
        time.sleep(1)  # é¿å… API é™åˆ¶
    
    # 4. ç¸½çµå ±å‘Š
    print("\n" + "="*60)
    print("ğŸ“‹ æ¸¬è©¦çµæœç¸½çµèˆ‡å»ºè­°")
    print("="*60)
    
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    print(f"ç¸½æ¸¬è©¦æ•¸: {len(results)}")
    print(f"æˆåŠŸ: {len(successful)}")
    print(f"å¤±æ•—: {len(failed)}")
    
    if successful:
        print(f"\nâœ… æˆåŠŸçš„æ¸¬è©¦:")
        for result in successful:
            method = result['method']
            time_info = f"{result['processing_time']:.2f}ç§’"
            
            if 'quality' in result and result['quality']:
                quality = result['quality']
                quality_info = f" | æ®µè½æ•¸: {quality['segment_count']}, å¹³å‡: {quality['avg_length']:.1f}å­—ç¬¦, æœ€é•·: {quality['max_length']}å­—ç¬¦"
            else:
                quality_info = ""
            
            print(f"  - {method}: {time_info}{quality_info}")
    
    if failed:
        print(f"\nâŒ å¤±æ•—çš„æ¸¬è©¦:")
        for result in failed:
            print(f"  - {result['method']}: {result['error']}")
    
    # 5. é‡å°æ‚¨å•é¡Œçš„å…·é«”å»ºè­°
    print(f"\nğŸ¯ é‡å° SRT æ®µè½éé•·å•é¡Œçš„è§£æ±ºæ–¹æ¡ˆ:")
    
    # æ¯”è¼ƒåŸå§‹ SRT å’Œè‡ªå®šç¾© SRT
    original_result = next((r for r in results if r['method'] == 'whisper-1_original_srt' and r['success']), None)
    custom_result = next((r for r in results if r['method'] == 'whisper-1_word_level_custom' and r['success']), None)
    
    if original_result and custom_result:
        original_quality = original_result['quality']
        custom_quality = custom_result['quality']
        
        print(f"\nğŸ“Š å“è³ªæ¯”è¼ƒ:")
        print(f"åŸå§‹ SRT  - æœ€é•·æ®µè½: {original_quality['max_length']} å­—ç¬¦, å¹³å‡: {original_quality['avg_length']:.1f} å­—ç¬¦")
        print(f"è‡ªå®šç¾© SRT - æœ€é•·æ®µè½: {custom_quality['max_length']} å­—ç¬¦, å¹³å‡: {custom_quality['avg_length']:.1f} å­—ç¬¦")
        
        if custom_quality['max_length'] < original_quality['max_length']:
            print("ğŸ‰ è‡ªå®šç¾© SRT æˆåŠŸè§£æ±ºäº†æ®µè½éé•·å•é¡Œï¼")
        else:
            print("âš ï¸  é€™å€‹éŸ³æª”çš„æ®µè½é•·åº¦æœ¬èº«å°±ä¸ç®—å¤ªé•·ï¼Œå¯èƒ½éœ€è¦ç”¨å…¶ä»–éŸ³æª”æ¸¬è©¦")
    
    print(f"\nğŸ’¡ æœ€çµ‚å»ºè­°:")
    print(f"1. å¦‚æœæ‚¨çš„éŸ³æª”ç¢ºå¯¦æœ‰æ®µè½éé•·å•é¡Œï¼Œä½¿ç”¨ whisper-1 + timestamp_granularities=['segment', 'word'] + è‡ªå®šç¾©è½‰æ›")
    print(f"2. æ–°æ¨¡å‹ (gpt-4o-transcribe/gpt-4o-mini-transcribe) è½‰éŒ„å“è³ªæ›´å¥½ï¼Œä½†ä¸æ”¯æ´ç›´æ¥ SRT è¼¸å‡º")
    print(f"3. å¯ä»¥çµåˆä½¿ç”¨ï¼šæ–°æ¨¡å‹è½‰éŒ„ + whisper-1 ç²å–æ™‚é–“æˆ³è¨˜ + è‡ªå®šç¾© SRT ç”Ÿæˆ")
    
    # ä¿å­˜å®Œæ•´çµæœ
    with open("correct_usage_test_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ’¾ å®Œæ•´æ¸¬è©¦çµæœå·²ä¿å­˜åˆ°: correct_usage_test_results.json")
    print("ğŸ‰ æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()
