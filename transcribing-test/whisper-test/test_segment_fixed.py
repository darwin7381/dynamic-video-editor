#!/usr/bin/env python3
"""
ä¿®æ­£ç‰ˆæ®µè½ç´šæ¸¬è©¦ - ä½¿ç”¨æ­£ç¢ºçš„ API åƒæ•¸
"""

import os
from dotenv import load_dotenv
import requests
import json
import time
from datetime import timedelta
import assemblyai as aai

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def format_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    td = timedelta(seconds=seconds)
    hours = int(td.total_seconds() // 3600)
    minutes = int((td.total_seconds() % 3600) // 60)
    seconds = td.total_seconds() % 60
    milliseconds = int((seconds % 1) * 1000)
    seconds = int(seconds)
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

def analyze_segment_quality(segments, service_name):
    """åˆ†ææ®µè½å“è³ª"""
    if not segments:
        return {
            'total_segments': 0,
            'avg_length': 0,
            'max_length': 0,
            'min_length': 0,
            'long_segments': 0,
            'score': 0
        }
    
    lengths = [len(seg['text']) for seg in segments]
    long_segments = sum(1 for length in lengths if length > 25)
    
    analysis = {
        'total_segments': len(segments),
        'avg_length': sum(lengths) / len(lengths) if lengths else 0,
        'max_length': max(lengths) if lengths else 0,
        'min_length': min(lengths) if lengths else 0,
        'long_segments': long_segments,
        'score': max(0, 60 - long_segments * 10)  # åŸºç¤è©•åˆ†é‚è¼¯
    }
    
    print(f"ğŸ“Š {service_name} æ®µè½ç´šåˆ†æ:")
    print(f"  ç¸½æ®µè½æ•¸: {analysis['total_segments']}")
    print(f"  å¹³å‡é•·åº¦: {analysis['avg_length']:.1f} å­—ç¬¦")
    print(f"  æœ€é•·æ®µè½: {analysis['max_length']} å­—ç¬¦")
    print(f"  æœ€çŸ­æ®µè½: {analysis['min_length']} å­—ç¬¦")
    print(f"  å•é¡Œæ®µè½: {analysis['long_segments']} å€‹ (>25å­—ç¬¦)")
    print(f"  æ®µè½æ§åˆ¶è©•åˆ†: {analysis['score']}/60")
    
    return analysis

def test_assemblyai_segment_fixed():
    """ä¿®æ­£ç‰ˆ AssemblyAI æ®µè½ç´šæ¸¬è©¦"""
    print(f"\nğŸš€ æ¸¬è©¦ AssemblyAI Universal-1 æ®µè½ç´šè¼¸å‡º (ä¿®æ­£ç‰ˆ)")
    print("=" * 60)
    
    api_key = os.getenv("ASSEMBLYAI_API_KEY")
    audio_file = "../audio-tts-mp3-20250523032437-WJdKQdwW.mp3"
    
    try:
        aai.settings.api_key = api_key
        
        # ä½¿ç”¨åŸºæœ¬é…ç½®ï¼Œä¸æŒ‡å®šç‰¹å®šæ¨¡å‹
        config = aai.TranscriptionConfig(
            language_code="zh",
            punctuate=True,
            format_text=True
        )
        
        print(f"ğŸ“¤ ä¸Šå‚³éŸ³æª”ä¸¦é–‹å§‹è½‰éŒ„...")
        transcriber = aai.Transcriber()
        transcript = transcriber.transcribe(audio_file, config)
        
        if transcript.status == aai.TranscriptStatus.error:
            print(f"âŒ AssemblyAI è½‰éŒ„å¤±æ•—: {transcript.error}")
            return None, [], {}
        
        print(f"âœ… AssemblyAI æ®µè½ç´šæ¸¬è©¦æˆåŠŸ")
        
        # ä½¿ç”¨ sentences ä½œç‚ºæ®µè½ç´šæ•¸æ“š
        segments = []
        if hasattr(transcript, 'sentences') and transcript.sentences:
            print(f"âœ… ç™¼ç¾å¥å­ç´šæ•¸æ“š: {len(transcript.sentences)} å€‹å¥å­")
            for sentence in transcript.sentences:
                segments.append({
                    'text': sentence.text,
                    'start': sentence.start / 1000.0,  # è½‰æ›ç‚ºç§’
                    'end': sentence.end / 1000.0
                })
        else:
            print(f"âš ï¸ æ²’æœ‰å¥å­ç´šæ•¸æ“šï¼Œä½¿ç”¨æ•´é«”æ–‡æœ¬")
            segments = [{
                'text': transcript.text,
                'start': 0,
                'end': transcript.audio_duration / 1000.0 if transcript.audio_duration else 30
            }]
        
        # ä¿å­˜çµæœ
        result_data = {
            'text': transcript.text,
            'confidence': transcript.confidence,
            'audio_duration': transcript.audio_duration,
            'segments': segments,
            'status': str(transcript.status)
        }
        
        with open("assemblyai_segment_result.json", "w", encoding="utf-8") as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆ SRT
        if segments:
            srt_content = ""
            for i, seg in enumerate(segments, 1):
                srt_content += f"{i}\n"
                srt_content += f"{format_time(seg['start'])} --> {format_time(seg['end'])}\n"
                srt_content += f"{seg['text']}\n\n"
            
            with open("assemblyai_segment_level.srt", "w", encoding="utf-8") as f:
                f.write(srt_content)
            print(f"ğŸ’¾ å·²ä¿å­˜: assemblyai_segment_level.srt")
        
        # åˆ†æå“è³ª
        analysis = analyze_segment_quality(segments, "AssemblyAI")
        return result_data, segments, analysis
        
    except Exception as e:
        print(f"âŒ AssemblyAI æ¸¬è©¦éŒ¯èª¤: {str(e)}")
        return None, [], {}

def test_groq_segment_fixed():
    """ä¿®æ­£ç‰ˆ Groq æ®µè½ç´šæ¸¬è©¦"""
    print(f"\nğŸš€ æ¸¬è©¦ Groq Whisper Large v3 æ®µè½ç´šè¼¸å‡º (ä¿®æ­£ç‰ˆ)")
    print("=" * 60)
    
    # ä½¿ç”¨æ­£ç¢ºçš„ Groq API Key
    api_key = os.getenv("GROQ_API_KEY")
    audio_file = "../audio-tts-mp3-20250523032437-WJdKQdwW.mp3"
    
    try:
        url = "https://api.groq.com/openai/v1/audio/transcriptions"
        headers = {
            "Authorization": f"Bearer {api_key}"
        }
        
        with open(audio_file, 'rb') as f:
            files = {
                "file": (audio_file, f, "audio/mpeg")
            }
            data = {
                "model": "whisper-large-v3",
                "response_format": "verbose_json",
                "language": "zh"
                # é è¨­æ‡‰è©²çµ¦æ®µè½ç´šçš„ segments
            }
            
            print(f"ğŸ“¤ ç™¼é€è«‹æ±‚...")
            response = requests.post(url, headers=headers, files=files, data=data, timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… Groq æ®µè½ç´šæ¸¬è©¦æˆåŠŸ")
                
                # ä¿å­˜çµæœ
                with open("groq_segment_result.json", "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                
                # æª¢æŸ¥æ®µè½æ•¸æ“š
                segments = []
                if 'segments' in result and result['segments']:
                    print(f"âœ… ç™¼ç¾æ®µè½ç´šæ•¸æ“š: {len(result['segments'])} å€‹æ®µè½")
                    segments = [{'text': seg.get('text', ''), 'start': seg.get('start', 0), 'end': seg.get('end', 0)} 
                               for seg in result['segments']]
                else:
                    print(f"âš ï¸ æ²’æœ‰æ®µè½ç´šæ•¸æ“šï¼Œä½¿ç”¨æ•´é«”æ–‡æœ¬")
                    segments = [{
                        'text': result.get('text', ''),
                        'start': 0,
                        'end': result.get('duration', 30)
                    }]
                
                # ç”Ÿæˆ SRT
                if segments:
                    srt_content = ""
                    for i, seg in enumerate(segments, 1):
                        srt_content += f"{i}\n"
                        srt_content += f"{format_time(seg['start'])} --> {format_time(seg['end'])}\n"
                        srt_content += f"{seg['text']}\n\n"
                    
                    with open("groq_segment_level.srt", "w", encoding="utf-8") as f:
                        f.write(srt_content)
                    print(f"ğŸ’¾ å·²ä¿å­˜: groq_segment_level.srt")
                
                # åˆ†æå“è³ª
                analysis = analyze_segment_quality(segments, "Groq")
                return result, segments, analysis
                
            else:
                print(f"âŒ Groq è«‹æ±‚å¤±æ•—: {response.status_code} - {response.text}")
                # å˜—è©¦ä½¿ç”¨ä¹‹å‰çš„çµæœæ–‡ä»¶
                try:
                    with open("groq_whisper_large_v3_result.json", "r", encoding="utf-8") as f:
                        result = json.load(f)
                        print(f"ğŸ”„ ä½¿ç”¨ä¹‹å‰çš„ Groq çµæœé€²è¡Œæ®µè½åˆ†æ")
                        
                        segments = []
                        if 'segments' in result:
                            segments = [{'text': seg.get('text', ''), 'start': seg.get('start', 0), 'end': seg.get('end', 0)} 
                                       for seg in result['segments']]
                        
                        analysis = analyze_segment_quality(segments, "Groq (å¿«å–)")
                        return result, segments, analysis
                except:
                    return None, [], {}
                
    except Exception as e:
        print(f"âŒ Groq æ¸¬è©¦éŒ¯èª¤: {str(e)}")
        return None, [], {}

def compare_detailed_results():
    """è©³ç´°æ¯”è¼ƒæ®µè½ç´šèˆ‡è©å½™ç´šçµæœ"""
    print(f"\nğŸ“Š è©³ç´°æ¯”è¼ƒåˆ†æ")
    print("=" * 80)
    
    # è®€å– ElevenLabs æ®µè½ç´šçµæœ
    try:
        with open("elevenlabs_segment_level.srt", "r", encoding="utf-8") as f:
            elevenlabs_segment_content = f.read()
        print(f"âœ… ElevenLabs æ®µè½ç´š SRT å·²è®€å–")
    except:
        elevenlabs_segment_content = ""
    
    # è®€å– ElevenLabs è©å½™ç´šçµæœ (ä¹‹å‰çš„æœ€ä½³ç‰ˆæœ¬)
    try:
        with open("elevenlabs_precise_18chars.srt", "r", encoding="utf-8") as f:
            elevenlabs_word_content = f.read()
        print(f"âœ… ElevenLabs è©å½™ç´š SRT å·²è®€å–")
    except:
        elevenlabs_word_content = ""
    
    print(f"\nğŸ“‹ ElevenLabs å°æ¯”:")
    segment_count = elevenlabs_segment_content.count('\n\n') if elevenlabs_segment_content else 0
    word_count = elevenlabs_word_content.count('\n\n') if elevenlabs_word_content else 0
    print(f"  æ®µè½ç´šæ®µè½æ•¸: {segment_count}")
    print(f"  è©å½™ç´šæ®µè½æ•¸: {word_count}")
    
    # é¡¯ç¤ºå‰3å€‹æ®µè½çš„å°æ¯”
    if elevenlabs_segment_content and elevenlabs_word_content:
        print(f"\nğŸ“ å‰3å€‹æ®µè½å°æ¯”:")
        
        segment_blocks = elevenlabs_segment_content.split('\n\n')[:3]
        word_blocks = elevenlabs_word_content.split('\n\n')[:3]
        
        for i, (seg_block, word_block) in enumerate(zip(segment_blocks, word_blocks), 1):
            if len(seg_block.split('\n')) >= 3 and len(word_block.split('\n')) >= 3:
                seg_text = seg_block.split('\n')[2]
                word_text = word_block.split('\n')[2]
                
                print(f"\n  æ®µè½ {i}:")
                print(f"    æ®µè½ç´š: {seg_text} ({len(seg_text)} å­—ç¬¦)")
                print(f"    è©å½™ç´š: {word_text} ({len(word_text)} å­—ç¬¦)")

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ¯ æ®µè½ç´šæ¸¬è©¦ (ä¿®æ­£ç‰ˆ)")
    print("=" * 80)
    
    results = {}
    
    # æ¸¬è©¦ AssemblyAI æ®µè½ç´š
    assemblyai_result, assemblyai_segments, assemblyai_analysis = test_assemblyai_segment_fixed()
    results['AssemblyAI'] = {
        'result': assemblyai_result,
        'segments': assemblyai_segments,
        'analysis': assemblyai_analysis
    }
    
    time.sleep(2)
    
    # æ¸¬è©¦ Groq æ®µè½ç´š
    groq_result, groq_segments, groq_analysis = test_groq_segment_fixed()
    results['Groq'] = {
        'result': groq_result,
        'segments': groq_segments,
        'analysis': groq_analysis
    }
    
    # è©³ç´°æ¯”è¼ƒ
    compare_detailed_results()
    
    # ç¸½çµæ¯”è¼ƒ
    print(f"\nğŸ† æ®µè½ç´š vs è©å½™ç´šç¸½çµ")
    print("=" * 60)
    
    comparison_table = [
        ["æœå‹™", "æ®µè½ç´šè©•åˆ†", "è©å½™ç´šè©•åˆ†", "æ¨è–¦ä½¿ç”¨"],
        ["ElevenLabs", "0/60 (é•·æ®µè½)", "100/100 (å®Œç¾)", "è©å½™ç´š"],
        ["AssemblyAI", f"{assemblyai_analysis.get('score', 0)}/60", "82/100", "çœ‹éœ€æ±‚"],
        ["Groq", f"{groq_analysis.get('score', 0)}/60", "95/100", "è©å½™ç´š"]
    ]
    
    for row in comparison_table:
        print(f"{row[0]:<12} {row[1]:<15} {row[2]:<15} {row[3]:<10}")
    
    print(f"\nğŸ’¡ é‡è¦çµè«–:")
    print(f"  âœ… è©å½™ç´šæ§åˆ¶æ˜é¡¯å„ªæ–¼æ®µè½ç´š")
    print(f"  âœ… ElevenLabs è©å½™ç´šä»æ˜¯æœ€ä½³é¸æ“‡")
    print(f"  âœ… æ®µè½ç´šé©åˆé–±è®€ï¼Œè©å½™ç´šé©åˆå­—å¹•")
    
    return results

if __name__ == "__main__":
    main()
