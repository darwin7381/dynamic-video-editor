#!/usr/bin/env python3
"""
ç²¾æº–çš„è©å½™ç´šæ™‚é–“æˆ³è¨˜æ¸¬è©¦
ä¿®å¾© AssemblyAI è§£æå•é¡Œï¼Œå…¬å¹³æ¯”è¼ƒå…©å€‹æœå‹™
"""

import os
import json

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def create_precise_srt_from_words(words, service_name, target_chars=18):
    """ç²¾ç¢ºå¾è©å½™ç´šæ™‚é–“æˆ³è¨˜å‰µå»º SRT"""
    if not words:
        return "ç„¡è©å½™è³‡è¨Š"
    
    segments = []
    current_segment = {
        'start': None,
        'end': None,
        'text': ''
    }
    
    for word in words:
        # è™•ç†ä¸åŒæœå‹™çš„æ ¼å¼
        if service_name == "ElevenLabs":
            word_text = word['text'].strip()
            start_time = word['start']
            end_time = word['end']
        else:  # AssemblyAI
            word_text = word['text'].strip()
            start_time = word['start'] / 1000  # è½‰æ›ç‚ºç§’
            end_time = word['end'] / 1000
        
        if not word_text:
            continue
            
        # æ™ºèƒ½åˆ†æ®µé‚è¼¯
        if current_segment['start'] is None:
            current_segment['start'] = start_time
            current_segment['end'] = end_time
            current_segment['text'] = word_text
        elif len(current_segment['text'] + word_text) > target_chars:
            # å®Œæˆç•¶å‰æ®µè½
            segments.append(current_segment.copy())
            # é–‹å§‹æ–°æ®µè½
            current_segment = {
                'start': start_time,
                'end': end_time,
                'text': word_text
            }
        else:
            # æ·»åŠ åˆ°ç•¶å‰æ®µè½
            current_segment['text'] += word_text
            current_segment['end'] = end_time
    
    # æ·»åŠ æœ€å¾Œä¸€å€‹æ®µè½
    if current_segment['text']:
        segments.append(current_segment)
    
    # ç”Ÿæˆ SRT
    srt_content = []
    for i, segment in enumerate(segments, 1):
        start_time = format_srt_time(segment['start'])
        end_time = format_srt_time(segment['end'])
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(segment['text'])
        srt_content.append("")
    
    return "\n".join(srt_content), segments

def analyze_service_capabilities(data, service_name):
    """åˆ†ææœå‹™çš„è©³ç´°èƒ½åŠ›"""
    print(f"\nğŸ” {service_name} è©³ç´°èƒ½åŠ›åˆ†æ")
    print("=" * 60)
    
    if service_name == "ElevenLabs":
        transcript_text = data['text']
        words = data['words']
        
        print(f"ğŸ“Š åŸºæœ¬è³‡è¨Š:")
        print(f"  èªè¨€æª¢æ¸¬: {data.get('language_code', 'N/A')}")
        print(f"  èªè¨€ä¿¡å¿ƒåº¦: {data.get('language_probability', 'N/A')}")
        print(f"  è½‰éŒ„æ–‡å­—é•·åº¦: {len(transcript_text)} å­—ç¬¦")
        print(f"  è©å½™æ•¸é‡: {len(words)} å€‹")
        
        print(f"\nğŸ” åŠŸèƒ½æ”¯æ´:")
        print(f"  âœ… è©å½™ç´šæ™‚é–“æˆ³è¨˜: {len(words)} å€‹è©å½™")
        print(f"  âŒ å¤šäººè¾¨è­˜: ä¸æ”¯æ´")
        
        # æª¢æŸ¥è©å½™ç´šæ™‚é–“æˆ³è¨˜å“è³ª
        if words:
            time_gaps = []
            for i in range(1, min(10, len(words))):
                gap = words[i]['start'] - words[i-1]['end']
                time_gaps.append(gap)
            
            avg_gap = sum(time_gaps) / len(time_gaps) if time_gaps else 0
            print(f"  ğŸ“ è©å½™é–“éš”å¹³å‡: {avg_gap:.3f} ç§’ (æ™‚é–“æˆ³è¨˜ç²¾ç¢ºåº¦)")
        
    else:  # AssemblyAI
        transcript_text = data['text']
        words = data.get('words', [])
        
        print(f"ğŸ“Š åŸºæœ¬è³‡è¨Š:")
        print(f"  èªè¨€è¨­å®š: {data.get('language_code', 'N/A')}")
        print(f"  è½‰éŒ„ç‹€æ…‹: {data.get('status', 'N/A')}")
        print(f"  è½‰éŒ„æ–‡å­—é•·åº¦: {len(transcript_text)} å­—ç¬¦")
        print(f"  è©å½™æ•¸é‡: {len(words)} å€‹")
        
        print(f"\nğŸ” åŠŸèƒ½æ”¯æ´:")
        if words:
            print(f"  âœ… è©å½™ç´šæ™‚é–“æˆ³è¨˜: {len(words)} å€‹è©å½™")
            
            # æª¢æŸ¥èªªè©±è€…æ¨™è­˜
            speakers = set()
            for word in words[:20]:  # æª¢æŸ¥å‰20å€‹è©å½™
                if 'speaker' in word:
                    speakers.add(word['speaker'])
            
            if speakers:
                print(f"  âœ… å¤šäººè¾¨è­˜: {len(speakers)} å€‹èªªè©±è€… ({', '.join(speakers)})")
            else:
                print(f"  âŒ å¤šäººè¾¨è­˜: æœªæª¢æ¸¬åˆ°èªªè©±è€…æ¨™è­˜")
            
            # æª¢æŸ¥ä¿¡å¿ƒåº¦
            confidences = [word.get('confidence', 0) for word in words[:10]]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            print(f"  ğŸ“Š è½‰éŒ„ä¿¡å¿ƒåº¦: {avg_confidence:.3f} (å‰10å€‹è©å½™å¹³å‡)")
        else:
            print(f"  âŒ è©å½™ç´šæ™‚é–“æˆ³è¨˜: ä¸æ”¯æ´")
    
    return transcript_text, words

def precise_quality_comparison(transcript_text, srt_segments, service_name):
    """ç²¾ç¢ºçš„å“è³ªæ¯”è¼ƒ"""
    print(f"\nğŸ“Š {service_name} ç²¾ç¢ºå“è³ªè©•ä¼°")
    print("=" * 60)
    
    # æ®µè½æ§åˆ¶åˆ†æ
    lengths = [len(seg['text']) for seg in srt_segments]
    max_length = max(lengths)
    avg_length = sum(lengths) / len(lengths)
    problem_count = sum(1 for l in lengths if l > 30)
    very_long_count = sum(1 for l in lengths if l > 40)
    ideal_count = sum(1 for l in lengths if 15 <= l <= 25)
    
    print(f"ğŸ“ æ®µè½æ§åˆ¶:")
    print(f"  ç¸½æ®µè½æ•¸: {len(srt_segments)}")
    print(f"  æœ€é•·æ®µè½: {max_length} å­—ç¬¦")
    print(f"  å¹³å‡é•·åº¦: {avg_length:.1f} å­—ç¬¦")
    print(f"  ç†æƒ³æ®µè½ (15-25å­—ç¬¦): {ideal_count} å€‹ ({ideal_count/len(srt_segments)*100:.1f}%)")
    print(f"  å•é¡Œæ®µè½ (>30å­—ç¬¦): {problem_count} å€‹")
    print(f"  åš´é‡å•é¡Œ (>40å­—ç¬¦): {very_long_count} å€‹")
    
    # è½‰éŒ„å“è³ªåˆ†æ
    punctuation_count = transcript_text.count('ï¼Œ') + transcript_text.count('ã€‚') + transcript_text.count('ï¼') + transcript_text.count('ï¼Ÿ')
    punctuation_count += transcript_text.count(',') + transcript_text.count('.') + transcript_text.count('!') + transcript_text.count('?')
    
    # å°ˆæ¥­è¡“èªè­˜åˆ¥ (ä¸å€åˆ†ç°¡ç¹é«”)
    terms_found = 0
    term_details = []
    
    if 'å°ç©é›»' in transcript_text or 'å°ç§¯ç”µ' in transcript_text:
        terms_found += 1
        term_details.append('å°ç©é›»/å°ç§¯ç”µ âœ…')
    
    if 'NVIDIA' in transcript_text or 'è¼é”' in transcript_text or 'è¾‰è¾¾' in transcript_text:
        terms_found += 1
        term_details.append('NVIDIA/è¼é”/è¾‰è¾¾ âœ…')
    
    if 'ç´æ–¯é”å…‹' in transcript_text or 'é‚£æ–¯è¾¾å…‹' in transcript_text:
        terms_found += 1
        term_details.append('ç´æ–¯é”å…‹/é‚£æ–¯è¾¾å…‹ âœ…')
    
    if 'æ¯”ç‰¹å¹£' in transcript_text or 'æ¯”ç‰¹å¸' in transcript_text:
        terms_found += 1
        term_details.append('æ¯”ç‰¹å¹£/æ¯”ç‰¹å¸ âœ…')
    
    print(f"\nğŸ“ è½‰éŒ„å“è³ª:")
    print(f"  æ¨™é»ç¬¦è™Ÿ: {punctuation_count} å€‹")
    print(f"  å°ˆæ¥­è¡“èª: {terms_found}/4 å€‹")
    for term in term_details:
        print(f"    - {term}")
    
    # é¡¯ç¤ºæœ€ä½³æ®µè½ç¤ºä¾‹
    print(f"\nğŸ“‹ æ®µè½å“è³ªç¤ºä¾‹:")
    ideal_segments = [seg for seg in srt_segments if 15 <= len(seg['text']) <= 25]
    if ideal_segments:
        print(f"  ç†æƒ³æ®µè½ç¤ºä¾‹:")
        for seg in ideal_segments[:3]:
            print(f"    ({len(seg['text'])}å­—ç¬¦) {seg['text']}")
    
    if problem_count > 0:
        problem_segments = [seg for seg in srt_segments if len(seg['text']) > 30]
        print(f"  å•é¡Œæ®µè½ç¤ºä¾‹:")
        for seg in problem_segments[:2]:
            print(f"    ({len(seg['text'])}å­—ç¬¦) {seg['text'][:50]}...")
    
    # è¨ˆç®—å…¬å¹³è©•åˆ†
    segment_score = 0
    if max_length <= 18 and problem_count == 0:
        segment_score = 60
    elif max_length <= 20 and problem_count == 0:
        segment_score = 55
    elif max_length <= 25 and problem_count == 0:
        segment_score = 50
    elif max_length <= 30 and very_long_count == 0:
        segment_score = 40
    else:
        segment_score = 30
    
    accuracy_score = min(punctuation_count * 1.5, 15) + terms_found * 6.25
    total_score = segment_score + accuracy_score
    
    print(f"\nğŸ“ˆ ç²¾ç¢ºè©•åˆ†:")
    print(f"  æ®µè½æ§åˆ¶: {segment_score}/60")
    print(f"  è½‰éŒ„æº–ç¢ºåº¦: {accuracy_score:.1f}/40")
    print(f"  ç¸½è©•åˆ†: {total_score:.1f}/100")
    
    return {
        'total_score': total_score,
        'segment_score': segment_score,
        'accuracy_score': accuracy_score,
        'max_length': max_length,
        'problem_count': problem_count,
        'ideal_count': ideal_count,
        'terms_found': terms_found,
        'punctuation_count': punctuation_count
    }

def main():
    """ç²¾æº–æ¸¬è©¦ä¸¦å…¬å¹³æ¯”è¼ƒ"""
    print("ğŸ¯ ç²¾æº–è©å½™ç´šæ¸¬è©¦ - å…¬å¹³æ¯”è¼ƒ ElevenLabs å’Œ AssemblyAI")
    print("=" * 80)
    
    results = []
    
    # 1. ç²¾æº–åˆ†æ ElevenLabs
    print(f"\nğŸ“Š ç²¾æº–åˆ†æ ElevenLabs Scribe V1")
    try:
        with open("elevenlabs_scribe_v1_result.json", "r", encoding="utf-8") as f:
            elevenlabs_data = json.load(f)
        
        transcript_text, words = analyze_service_capabilities(elevenlabs_data, "ElevenLabs")
        
        # å‰µå»ºæœ€ä½³ SRT
        srt_content, segments = create_precise_srt_from_words(words, "ElevenLabs", target_chars=18)
        
        with open("elevenlabs_precise_18chars.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        print(f"ğŸ’¾ ç²¾æº– SRT å·²ä¿å­˜: elevenlabs_precise_18chars.srt")
        
        # ç²¾ç¢ºè©•ä¼°
        analysis = precise_quality_comparison(transcript_text, segments, "ElevenLabs Scribe")
        results.append(('ElevenLabs Scribe', analysis))
        
    except Exception as e:
        print(f"âŒ ElevenLabs åˆ†æå¤±æ•—: {str(e)}")
    
    # 2. ç²¾æº–åˆ†æ AssemblyAI (ä¿®å¾©è§£æ)
    print(f"\nğŸ“Š ç²¾æº–åˆ†æ AssemblyAI Universal-1 (ä¿®å¾©ç‰ˆ)")
    try:
        with open("assemblyai_chinese_result.json", "r", encoding="utf-8") as f:
            assemblyai_data = json.load(f)
        
        transcript_text, words = analyze_service_capabilities(assemblyai_data, "AssemblyAI")
        
        # å‰µå»ºæœ€ä½³ SRT (ä¿®å¾©ç‰ˆ)
        srt_content, segments = create_precise_srt_from_words(words, "AssemblyAI", target_chars=18)
        
        with open("assemblyai_precise_18chars.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        print(f"ğŸ’¾ ç²¾æº– SRT å·²ä¿å­˜: assemblyai_precise_18chars.srt")
        
        # ç²¾ç¢ºè©•ä¼°
        analysis = precise_quality_comparison(transcript_text, segments, "AssemblyAI Universal-1")
        results.append(('AssemblyAI Universal-1', analysis))
        
    except Exception as e:
        print(f"âŒ AssemblyAI åˆ†æå¤±æ•—: {str(e)}")
    
    # 3. æœ€çµ‚ç²¾æº–æ¯”è¼ƒ
    print(f"\n" + "=" * 80)
    print(f"ğŸ† ç²¾æº–æ¯”è¼ƒçµæœ - è©å½™ç´šèƒ½åŠ›å…¬å¹³å°æ±º")
    print("=" * 80)
    
    # é‡æ–°è©•ä¼° Groq æœ€ä½³æ–¹æ¡ˆ (å…¬å¹³è©•åˆ†)
    groq_best_score = 60 + 25.2  # æ®µè½æ§åˆ¶60 + è½‰éŒ„å“è³ª25.2 (å»é™¤ç¹é«”å„ªå‹¢)
    
    print(f"ğŸ“Š åŸºæº–æ¯”è¼ƒ:")
    print(f"  Groq + Prompt + è©å½™ç´š (é‡æ–°è©•åˆ†): {groq_best_score:.1f}/100")
    print(f"    æ®µè½æ§åˆ¶: 60/60 (18å­—ç¬¦)")
    print(f"    è½‰éŒ„æº–ç¢ºåº¦: 25.2/40 (7å€‹æ¨™é»ç¬¦è™Ÿ + 3å€‹è¡“èª)")
    
    if results:
        print(f"\nğŸ“ˆ æ–°æœå‹™è©å½™ç´šèƒ½åŠ›æ’å:")
        
        # æŒ‰è©•åˆ†æ’åº
        results.sort(key=lambda x: x[1]['total_score'], reverse=True)
        
        for i, (service_name, analysis) in enumerate(results, 1):
            print(f"\n  {i}. {service_name}: {analysis['total_score']:.1f}/100")
            print(f"     æ®µè½æ§åˆ¶: {analysis['segment_score']}/60 (æœ€é•· {analysis['max_length']} å­—ç¬¦)")
            print(f"     è½‰éŒ„æº–ç¢ºåº¦: {analysis['accuracy_score']:.1f}/40")
            print(f"     ç†æƒ³æ®µè½: {analysis['ideal_count']} å€‹")
            print(f"     å•é¡Œæ®µè½: {analysis['problem_count']} å€‹")
            print(f"     å°ˆæ¥­è¡“èª: {analysis['terms_found']}/4 å€‹")
            print(f"     æ¨™é»ç¬¦è™Ÿ: {analysis['punctuation_count']} å€‹")
            
            # èˆ‡ Groq æ¯”è¼ƒ
            score_diff = analysis['total_score'] - groq_best_score
            if score_diff > 5:
                print(f"     ğŸ‰ æ¯” Groq æœ€ä½³æ–¹æ¡ˆå¥½ {score_diff:.1f} åˆ†ï¼")
            elif score_diff > 0:
                print(f"     âœ… æ¯” Groq æœ€ä½³æ–¹æ¡ˆç•¥å¥½ (+{score_diff:.1f})")
            elif score_diff > -5:
                print(f"     âš ï¸ æ¥è¿‘ Groq æœ€ä½³æ–¹æ¡ˆ ({score_diff:.1f})")
            else:
                print(f"     âŒ ä¸å¦‚ Groq æœ€ä½³æ–¹æ¡ˆ ({score_diff:.1f})")
        
        # æœ€çµ‚çµè«–
        best_service = results[0]
        if best_service[1]['total_score'] > groq_best_score:
            print(f"\nğŸ‰ ç¢ºèªç™¼ç¾æ›´å¥½çš„æ–¹æ¡ˆï¼")
            print(f"ğŸ† æ–°çš„è©å½™ç´šå† è»: {best_service[0]}")
            print(f"   è©•åˆ†: {best_service[1]['total_score']:.1f}/100")
            print(f"   å„ªå‹¢: æ¯” Groq å¥½ {best_service[1]['total_score'] - groq_best_score:.1f} åˆ†")
        else:
            print(f"\nğŸ“Š çµè«–: Groq æœ€ä½³æ–¹æ¡ˆä»ç„¶é ˜å…ˆ")
    
    print(f"\nğŸ‰ ç²¾æº–è©å½™ç´šæ¸¬è©¦å®Œæˆï¼")
    return results

if __name__ == "__main__":
    main()
