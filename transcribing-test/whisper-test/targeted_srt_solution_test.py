#!/usr/bin/env python3
"""
é‡å° SRT æ®µè½éé•·å•é¡Œçš„å°ˆæ¥­è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦
ä½¿ç”¨å°ˆæ¥­è¨­è¨ˆçš„ Prompt
"""

import os
from dotenv import load_dotenv
import time
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def create_srt_from_segments(segments):
    """å¾æ®µè½è³‡è¨Šå‰µå»º SRT"""
    srt_content = []
    
    for i, segment in enumerate(segments, 1):
        start_time = format_srt_time(segment.start)
        end_time = format_srt_time(segment.end)
        text = segment.text.strip()
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)

def analyze_subtitle_quality(srt_content, model_name):
    """åˆ†æå­—å¹•å“è³ª - å°ˆæ³¨æ–¼å¯¦éš›ä½¿ç”¨é«”é©—"""
    print(f"\nğŸ“º {model_name} - å­—å¹•å¯¦ç”¨æ€§åˆ†æ")
    print("=" * 50)
    
    lines = srt_content.strip().split('\n')
    segments = []
    
    i = 0
    while i < len(lines):
        if lines[i].strip().isdigit():
            segment_id = int(lines[i])
            if i + 2 < len(lines):
                time_line = lines[i + 1]
                text_lines = []
                i += 2
                while i < len(lines) and lines[i].strip():
                    text_lines.append(lines[i])
                    i += 1
                
                if text_lines:
                    text = ' '.join(text_lines).strip()
                    segments.append({
                        'id': segment_id,
                        'time': time_line,
                        'text': text,
                        'length': len(text)
                    })
        i += 1
    
    if not segments:
        print("âŒ ç„¡æ³•è§£æ SRT å…§å®¹")
        return None
    
    # å¯¦éš›å­—å¹•å“è³ªè©•ä¼°
    print(f"ğŸ“Š å­—å¹•åŸºæœ¬è³‡è¨Š:")
    print(f"  æ®µè½ç¸½æ•¸: {len(segments)}")
    
    lengths = [seg['length'] for seg in segments]
    avg_length = sum(lengths) / len(lengths)
    
    print(f"  å¹³å‡é•·åº¦: {avg_length:.1f} å­—ç¬¦")
    print(f"  æœ€é•·æ®µè½: {max(lengths)} å­—ç¬¦")
    print(f"  æœ€çŸ­æ®µè½: {min(lengths)} å­—ç¬¦")
    
    # å­—å¹•è§€çœ‹é«”é©—åˆ†æ
    print(f"\nğŸ“º è§€çœ‹é«”é©—åˆ†æ:")
    
    # ç†æƒ³å­—å¹•é•·åº¦ (15-35 å­—ç¬¦ï¼Œé©åˆè¢å¹•é¡¯ç¤º)
    ideal_count = sum(1 for l in lengths if 15 <= l <= 35)
    short_count = sum(1 for l in lengths if l < 15)
    long_count = sum(1 for l in lengths if l > 35)
    very_long_count = sum(1 for l in lengths if l > 50)
    
    print(f"  ç†æƒ³é•·åº¦ (15-35å­—ç¬¦): {ideal_count} å€‹ ({ideal_count/len(segments)*100:.1f}%)")
    print(f"  éçŸ­ (<15å­—ç¬¦): {short_count} å€‹ ({short_count/len(segments)*100:.1f}%)")
    print(f"  éé•· (>35å­—ç¬¦): {long_count} å€‹ ({long_count/len(segments)*100:.1f}%)")
    print(f"  åš´é‡éé•· (>50å­—ç¬¦): {very_long_count} å€‹ ({very_long_count/len(segments)*100:.1f}%)")
    
    # å…§å®¹å“è³ªåˆ†æ
    print(f"\nğŸ“– å…§å®¹å“è³ªæª¢æŸ¥:")
    print(f"å¯¦éš›å­—å¹•å…§å®¹ (å‰ 6 å€‹æ®µè½):")
    
    quality_issues = []
    
    for seg in segments[:6]:
        text = seg['text']
        time_info = seg['time']
        length = seg['length']
        
        # æª¢æŸ¥å„ç¨®å“è³ªæŒ‡æ¨™
        has_proper_ending = text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?'))
        has_punctuation = any(p in text for p in ['ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', ',', '.', '!', '?', 'ã€'])
        is_readable_length = 15 <= length <= 35
        
        # è©•ä¼°å­—å¹•å“è³ª
        quality_score = ""
        if is_readable_length:
            quality_score += "ğŸ“âœ…"
        else:
            quality_score += "ğŸ“âŒ"
            if length > 35:
                quality_issues.append(f"æ®µè½ {seg['id']} éé•· ({length} å­—ç¬¦)")
        
        if has_punctuation:
            quality_score += " ğŸ“âœ…"
        else:
            quality_score += " ğŸ“âŒ"
            quality_issues.append(f"æ®µè½ {seg['id']} ç¼ºå°‘æ¨™é»ç¬¦è™Ÿ")
        
        if has_proper_ending:
            quality_score += " ğŸ”šâœ…"
        else:
            quality_score += " ğŸ”šâŒ"
        
        print(f"  {seg['id']}. [{time_info}] ({length}å­—ç¬¦) {quality_score}")
        print(f"      {text}")
        print()
    
    # å•é¡Œç¸½çµ
    if quality_issues:
        print(f"âš ï¸ ç™¼ç¾çš„å“è³ªå•é¡Œ:")
        for issue in quality_issues[:5]:  # åªé¡¯ç¤ºå‰ 5 å€‹å•é¡Œ
            print(f"  - {issue}")
        if len(quality_issues) > 5:
            print(f"  - ... é‚„æœ‰ {len(quality_issues) - 5} å€‹å•é¡Œ")
    else:
        print(f"âœ… æ²’æœ‰ç™¼ç¾æ˜é¡¯çš„å“è³ªå•é¡Œ")
    
    # æ•´é«”è©•ç´š
    ideal_ratio = ideal_count / len(segments)
    long_ratio = long_count / len(segments)
    
    if ideal_ratio > 0.7 and long_ratio < 0.1:
        overall_rating = "ğŸ† å„ªç§€ - é©åˆç›´æ¥ä½¿ç”¨"
    elif ideal_ratio > 0.5 and long_ratio < 0.2:
        overall_rating = "âœ… è‰¯å¥½ - ç¨ä½œèª¿æ•´å³å¯"
    elif ideal_ratio > 0.3 and long_ratio < 0.4:
        overall_rating = "âš ï¸ ä¸€èˆ¬ - éœ€è¦å„ªåŒ–"
    else:
        overall_rating = "âŒ ä¸ä½³ - ä¸é©åˆå­—å¹•ä½¿ç”¨"
    
    print(f"\nğŸ¯ æ•´é«”è©•ç´š: {overall_rating}")
    
    return {
        'total_segments': len(segments),
        'avg_length': avg_length,
        'ideal_count': ideal_count,
        'long_count': long_count,
        'very_long_count': very_long_count,
        'ideal_ratio': ideal_ratio,
        'long_ratio': long_ratio,
        'quality_issues': quality_issues,
        'overall_rating': overall_rating
    }

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸ - é‡å°æ‚¨çš„å…·é«”å•é¡Œè¨­è¨ˆå°ˆæ¥­ Prompt"""
    
    # API è¨­å®š
    openai_api_key = os.getenv("OPENAI_API_KEY")
    groq_api_key = os.getenv("GROQ_API_KEY")
    
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” {audio_file}")
        return
    
    print("ğŸ¯ é‡å° SRT æ®µè½éé•·å•é¡Œçš„å°ˆæ¥­è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦")
    print("=" * 80)
    
    # æ ¹æ“šæ‚¨çš„å…·é«”å•é¡Œè¨­è¨ˆçš„å°ˆæ¥­ Prompt
    targeted_prompt = """è«‹è½‰éŒ„é€™æ®µè²¡ç¶“æ–°èéŸ³é »ï¼Œä¸¦ç¢ºä¿è¼¸å‡ºé©åˆè£½ä½œå­—å¹•ï¼š

è¦æ±‚ï¼š
1. æ¯å€‹æ®µè½æ§åˆ¶åœ¨ 20-30 å€‹ä¸­æ–‡å­—ç¬¦
2. åœ¨è‡ªç„¶çš„èªéŸ³åœé “è™•åˆ†æ®µ
3. ä¿æŒèªç¾©å®Œæ•´ï¼Œä¸è¦åœ¨å¥å­ä¸­é–“æ–·é–‹
4. æ­£ç¢ºè­˜åˆ¥å…¬å¸åç¨±ï¼šå°ç©é›»ã€è¯é›»ã€æ—¥æœˆå…‰ã€NVIDIAã€ADR
5. æ­£ç¢ºè­˜åˆ¥é‡‘èè¡“èªï¼šé‚£æ–¯é”å…‹ã€è²»åŠã€æ¯”ç‰¹å¹£
6. æ·»åŠ é©ç•¶çš„æ¨™é»ç¬¦è™Ÿï¼Œä½†ä¸è¦éåº¦ä½¿ç”¨

é€™æ˜¯ä¸€æ®µé—œæ–¼ä¸­ç¾è²¿æ˜“æˆ°å’Œè‚¡å¸‚å½±éŸ¿çš„æ–°èå…§å®¹ã€‚"""
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯
    openai_client = OpenAI(api_key=openai_api_key)
    groq_client = OpenAI(
        api_key=groq_api_key,
        base_url="https://api.groq.com/openai/v1"
    )
    
    test_results = []
    srt_analyses = {}
    
    # æ¸¬è©¦ 1: OpenAI whisper-1 (åŸºæº–)
    print(f"\nğŸ“Š æ¸¬è©¦ 1: OpenAI Whisper-1 (ç„¡ Prompt)")
    try:
        start_time = time.time()
        
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],
                language="zh"
            )
        
        processing_time = time.time() - start_time
        print(f"âœ… è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
        
        srt_content = create_srt_from_segments(transcription.segments)
        with open("whisper1_baseline.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        
        analysis = analyze_subtitle_quality(srt_content, "Whisper-1 åŸºæº–")
        srt_analyses["Whisper-1 åŸºæº–"] = analysis
        
        test_results.append({
            'model': 'whisper-1',
            'config': 'åŸºæº–æ¸¬è©¦',
            'processing_time': processing_time,
            'analysis': analysis
        })
        
    except Exception as e:
        print(f"âŒ Whisper-1 åŸºæº–æ¸¬è©¦å¤±æ•—: {str(e)}")
    
    # æ¸¬è©¦ 2: OpenAI whisper-1 (å°ˆæ¥­ Prompt)
    print(f"\nğŸ“Š æ¸¬è©¦ 2: OpenAI Whisper-1 (å°ˆæ¥­ Prompt)")
    try:
        start_time = time.time()
        
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],
                prompt=targeted_prompt,
                language="zh"
            )
        
        processing_time = time.time() - start_time
        print(f"âœ… è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
        
        srt_content = create_srt_from_segments(transcription.segments)
        with open("whisper1_professional_prompt.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        
        analysis = analyze_subtitle_quality(srt_content, "Whisper-1 å°ˆæ¥­Prompt")
        srt_analyses["Whisper-1 å°ˆæ¥­Prompt"] = analysis
        
        test_results.append({
            'model': 'whisper-1',
            'config': 'å°ˆæ¥­ Prompt',
            'processing_time': processing_time,
            'analysis': analysis
        })
        
    except Exception as e:
        print(f"âŒ Whisper-1 å°ˆæ¥­ Prompt æ¸¬è©¦å¤±æ•—: {str(e)}")
    
    # æ¸¬è©¦ 3: Groq Whisper Large v3 (ç„¡ Prompt)
    print(f"\nğŸ“Š æ¸¬è©¦ 3: Groq Whisper Large v3 (ç„¡ Prompt)")
    try:
        start_time = time.time()
        
        with open(audio_file, "rb") as f:
            transcription = groq_client.audio.transcriptions.create(
                model="whisper-large-v3",
                file=f,
                response_format="verbose_json",
                language="zh"
            )
        
        processing_time = time.time() - start_time
        print(f"âœ… è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
        
        srt_content = create_srt_from_segments(transcription.segments)
        with open("groq_large_v3_baseline.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        
        analysis = analyze_subtitle_quality(srt_content, "Groq Large v3 åŸºæº–")
        srt_analyses["Groq Large v3 åŸºæº–"] = analysis
        
        test_results.append({
            'model': 'groq-whisper-large-v3',
            'config': 'åŸºæº–æ¸¬è©¦',
            'processing_time': processing_time,
            'analysis': analysis
        })
        
    except Exception as e:
        print(f"âŒ Groq Large v3 åŸºæº–æ¸¬è©¦å¤±æ•—: {str(e)}")
    
    # æ¸¬è©¦ 4: Groq Whisper Large v3 (å°ˆæ¥­ Prompt)
    print(f"\nğŸ“Š æ¸¬è©¦ 4: Groq Whisper Large v3 (å°ˆæ¥­ Prompt)")
    try:
        start_time = time.time()
        
        with open(audio_file, "rb") as f:
            transcription = groq_client.audio.transcriptions.create(
                model="whisper-large-v3",
                file=f,
                response_format="verbose_json",
                prompt=targeted_prompt,
                language="zh"
            )
        
        processing_time = time.time() - start_time
        print(f"âœ… è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
        
        srt_content = create_srt_from_segments(transcription.segments)
        with open("groq_large_v3_professional_prompt.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        
        analysis = analyze_subtitle_quality(srt_content, "Groq Large v3 å°ˆæ¥­Prompt")
        srt_analyses["Groq Large v3 å°ˆæ¥­Prompt"] = analysis
        
        test_results.append({
            'model': 'groq-whisper-large-v3',
            'config': 'å°ˆæ¥­ Prompt',
            'processing_time': processing_time,
            'analysis': analysis
        })
        
    except Exception as e:
        print(f"âŒ Groq Large v3 å°ˆæ¥­ Prompt æ¸¬è©¦å¤±æ•—: {str(e)}")
    
    # æœ€çµ‚æ¯”è¼ƒå’Œæ¨è–¦
    print(f"\n" + "=" * 80)
    print(f"ğŸ† è§£æ±º SRT æ®µè½éé•·å•é¡Œ - æœ€çµ‚æ¨è–¦")
    print("=" * 80)
    
    if srt_analyses:
        # æŒ‰æ•´é«”è©•ç´šæ’åº
        best_solutions = []
        
        for name, analysis in srt_analyses.items():
            # è¨ˆç®—è§£æ±ºå•é¡Œçš„æ•ˆæœ
            problem_solving_score = 0
            
            # é•·æ®µè½æ§åˆ¶ (40%)
            if analysis['long_ratio'] < 0.1:
                problem_solving_score += 40
            elif analysis['long_ratio'] < 0.2:
                problem_solving_score += 30
            elif analysis['long_ratio'] < 0.3:
                problem_solving_score += 20
            
            # ç†æƒ³æ®µè½æ¯”ä¾‹ (30%)
            problem_solving_score += analysis['ideal_ratio'] * 30
            
            # æ²’æœ‰åš´é‡éé•·æ®µè½ (30%)
            if analysis['very_long_count'] == 0:
                problem_solving_score += 30
            elif analysis['very_long_count'] <= 2:
                problem_solving_score += 20
            
            best_solutions.append((name, analysis, problem_solving_score))
        
        # æ’åº
        best_solutions.sort(key=lambda x: x[2], reverse=True)
        
        print(f"ğŸ¯ è§£æ±ºæ–¹æ¡ˆæ’è¡Œæ¦œ:")
        for i, (name, analysis, score) in enumerate(best_solutions, 1):
            print(f"  {i}. {name} - å•é¡Œè§£æ±ºåº¦: {score:.1f}/100")
            print(f"     éé•·æ®µè½: {analysis['long_count']} å€‹ ({analysis['long_ratio']*100:.1f}%)")
            print(f"     ç†æƒ³æ®µè½: {analysis['ideal_count']} å€‹ ({analysis['ideal_ratio']*100:.1f}%)")
            print(f"     æ•´é«”è©•ç´š: {analysis['overall_rating']}")
            print()
        
        # æœ€çµ‚æ¨è–¦
        winner = best_solutions[0]
        print(f"ğŸ… æœ€ä½³è§£æ±ºæ–¹æ¡ˆ: {winner[0]}")
        print(f"   å•é¡Œè§£æ±ºåº¦: {winner[2]:.1f}/100")
        print(f"   {winner[1]['overall_rating']}")
    
    print(f"\nğŸ‰ é‡å°æ€§æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()
