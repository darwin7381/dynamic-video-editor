#!/usr/bin/env python3
"""
å®Œæ•´çš„æ®µè½ç´š vs è©å½™ç´šæ¯”è¼ƒåˆ†æ
åŒ…å« ElevenLabs, AssemblyAI, Groq ä¸‰å€‹æœå‹™
"""

import os
import json

def parse_srt_file(filepath):
    """è§£æ SRT æ–‡ä»¶ä¸¦è¿”å›æ®µè½ä¿¡æ¯"""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read().strip()
        
        blocks = content.split('\n\n')
        segments = []
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                segment_id = lines[0]
                timestamp = lines[1]
                text = lines[2]
                
                segments.append({
                    'id': segment_id,
                    'timestamp': timestamp,
                    'text': text,
                    'length': len(text)
                })
        
        return segments
    except Exception as e:
        print(f"âŒ ç„¡æ³•è§£æ {filepath}: {str(e)}")
        return []

def analyze_segments(segments, name, service, level_type):
    """åˆ†ææ®µè½ç‰¹æ€§"""
    if not segments:
        return None
    
    lengths = [seg['length'] for seg in segments]
    long_segments = [seg for seg in segments if seg['length'] > 25]
    very_long_segments = [seg for seg in segments if seg['length'] > 35]
    
    # è©•åˆ†é‚è¼¯ï¼šåŸºç¤60åˆ†ï¼Œæ¯å€‹é•·æ®µè½æ‰£5åˆ†ï¼Œæ¯å€‹è¶…é•·æ®µè½æ‰£é¡å¤–5åˆ†
    score = 60 - (len(long_segments) * 5) - (len(very_long_segments) * 5)
    
    analysis = {
        'name': name,
        'service': service,
        'level_type': level_type,
        'total_segments': len(segments),
        'avg_length': sum(lengths) / len(lengths),
        'max_length': max(lengths),
        'min_length': min(lengths),
        'long_segments_count': len(long_segments),
        'very_long_segments_count': len(very_long_segments),
        'score': max(0, score),
        'long_segments': long_segments,
        'very_long_segments': very_long_segments,
        'all_segments': segments
    }
    
    return analysis

def create_complete_comparison():
    """å‰µå»ºå®Œæ•´çš„ä¸‰æœå‹™æ¯”è¼ƒ"""
    print("ğŸ¯ å®Œæ•´æ®µè½ç´š vs è©å½™ç´šæ¯”è¼ƒåˆ†æ")
    print("=" * 80)
    
    # å®šç¾©æ‰€æœ‰è¦æ¯”è¼ƒçš„æ–‡ä»¶
    files_to_compare = [
        # æ®µè½ç´šæ–‡ä»¶
        ("elevenlabs_segment_real.srt", "ElevenLabs æ®µè½ç´š", "ElevenLabs", "segment"),
        ("assemblyai_segment_real.srt", "AssemblyAI æ®µè½ç´š", "AssemblyAI", "segment"),
        
        # è©å½™ç´šæ–‡ä»¶
        ("elevenlabs_precise_18chars.srt", "ElevenLabs è©å½™ç´š", "ElevenLabs", "word"),
        ("assemblyai_precise_18chars.srt", "AssemblyAI è©å½™ç´š", "AssemblyAI", "word"),
        ("final_groq_word_level.srt", "Groq è©å½™ç´š", "Groq", "word")
    ]
    
    analyses = []
    
    print("ğŸ“‹ è§£ææ‰€æœ‰æ–‡ä»¶...")
    for filepath, name, service, level_type in files_to_compare:
        if os.path.exists(filepath):
            file_size = os.path.getsize(filepath)
            print(f"  âœ… è§£æ {name}: {filepath} ({file_size} bytes)")
            segments = parse_srt_file(filepath)
            analysis = analyze_segments(segments, name, service, level_type)
            if analysis:
                analysis['filepath'] = filepath
                analyses.append(analysis)
        else:
            print(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    
    if not analyses:
        print("âŒ æ²’æœ‰å¯åˆ†æçš„æ–‡ä»¶")
        return None
    
    # é¡¯ç¤ºå®Œæ•´æ¯”è¼ƒè¡¨æ ¼
    print(f"\nğŸ“Š å®Œæ•´æ¯”è¼ƒçµæœ:")
    print(f"{'æœå‹™':<12} {'é¡å‹':<6} {'æ®µè½æ•¸':<8} {'å¹³å‡é•·åº¦':<8} {'æœ€é•·':<6} {'å•é¡Œæ®µè½':<8} {'è©•åˆ†':<6}")
    print("-" * 80)
    
    for analysis in analyses:
        print(f"{analysis['service']:<12} {analysis['level_type']:<6} {analysis['total_segments']:<8} "
              f"{analysis['avg_length']:<8.1f} {analysis['max_length']:<6} "
              f"{analysis['long_segments_count']:<8} {analysis['score']:<6.0f}")
    
    # æŒ‰æœå‹™åˆ†çµ„æ¯”è¼ƒ
    print(f"\nğŸ” æŒ‰æœå‹™åˆ†çµ„æ¯”è¼ƒ:")
    services = list(set(a['service'] for a in analyses))
    
    for service in services:
        service_analyses = [a for a in analyses if a['service'] == service]
        if len(service_analyses) >= 2:  # æœ‰æ®µè½ç´šå’Œè©å½™ç´š
            print(f"\n  ğŸ“ˆ {service} æ¯”è¼ƒ:")
            
            segment_analysis = next((a for a in service_analyses if a['level_type'] == 'segment'), None)
            word_analysis = next((a for a in service_analyses if a['level_type'] == 'word'), None)
            
            if segment_analysis and word_analysis:
                print(f"    æ®µè½ç´š: æœ€é•· {segment_analysis['max_length']} å­—ç¬¦, å•é¡Œæ®µè½ {segment_analysis['long_segments_count']} å€‹, è©•åˆ† {segment_analysis['score']:.0f}/60")
                print(f"    è©å½™ç´š: æœ€é•· {word_analysis['max_length']} å­—ç¬¦, å•é¡Œæ®µè½ {word_analysis['long_segments_count']} å€‹, è©•åˆ† {word_analysis['score']:.0f}/60")
                
                improvement = segment_analysis['max_length'] - word_analysis['max_length']
                score_improvement = word_analysis['score'] - segment_analysis['score']
                
                print(f"    æ”¹å–„: æœ€é•·æ®µè½æ¸›å°‘ {improvement} å­—ç¬¦, è©•åˆ†æå‡ {score_improvement:.0f} åˆ†")
                
                if improvement > 0 and score_improvement > 0:
                    print(f"    âœ… è©å½™ç´šæ˜é¡¯å„ªæ–¼æ®µè½ç´š")
                elif improvement > 0:
                    print(f"    âœ… è©å½™ç´šæ®µè½æ§åˆ¶æ›´å¥½")
                else:
                    print(f"    âš ï¸ å·®ç•°ä¸æ˜é¡¯")
    
    # åŒé¡å‹æ’å
    print(f"\nğŸ† åŒé¡å‹æœå‹™æ’å:")
    
    # æ®µè½ç´šæ’å
    segment_analyses = [a for a in analyses if a['level_type'] == 'segment']
    if segment_analyses:
        print(f"\n  æ®µè½ç´šæ’å:")
        segment_analyses.sort(key=lambda x: (-x['score'], x['max_length']))
        for i, analysis in enumerate(segment_analyses, 1):
            print(f"    {i}. {analysis['name']}: {analysis['score']:.0f}/60 (æœ€é•· {analysis['max_length']} å­—ç¬¦)")
    
    # è©å½™ç´šæ’å
    word_analyses = [a for a in analyses if a['level_type'] == 'word']
    if word_analyses:
        print(f"\n  è©å½™ç´šæ’å:")
        word_analyses.sort(key=lambda x: (-x['score'], x['max_length']))
        for i, analysis in enumerate(word_analyses, 1):
            print(f"    {i}. {analysis['name']}: {analysis['score']:.0f}/60 (æœ€é•· {analysis['max_length']} å­—ç¬¦)")
    
    return analyses

def show_problem_samples(analyses):
    """é¡¯ç¤ºå•é¡Œæ®µè½æ¨£æœ¬"""
    print(f"\nğŸ“ å•é¡Œæ®µè½æ¨£æœ¬ (>25å­—ç¬¦):")
    
    for analysis in analyses:
        if analysis['long_segments']:
            print(f"\n  {analysis['name']} å•é¡Œæ®µè½:")
            for i, seg in enumerate(analysis['long_segments'][:3], 1):  # åªé¡¯ç¤ºå‰3å€‹
                print(f"    {i}. {seg['text']} ({seg['length']} å­—ç¬¦)")
        else:
            print(f"\n  {analysis['name']}: âœ… ç„¡å•é¡Œæ®µè½")

def generate_final_comprehensive_report(analyses):
    """ç”Ÿæˆæœ€çµ‚ç¶œåˆå ±å‘Š"""
    print(f"\nğŸ† æœ€çµ‚ç¶œåˆå ±å‘Š")
    print("=" * 80)
    
    # çµ±è¨ˆæˆåŠŸæ¸¬è©¦
    segment_count = len([a for a in analyses if a['level_type'] == 'segment'])
    word_count = len([a for a in analyses if a['level_type'] == 'word'])
    
    print(f"ğŸ“Š æ¸¬è©¦æˆåŠŸçµ±è¨ˆ:")
    print(f"  æ®µè½ç´šæ¸¬è©¦: {segment_count} å€‹æœå‹™æˆåŠŸ")
    print(f"  è©å½™ç´šæ¸¬è©¦: {word_count} å€‹æœå‹™æˆåŠŸ")
    print(f"  ç¸½è¨ˆ: {len(analyses)} å€‹æ¸¬è©¦çµæœ")
    
    # æ‰¾å‡ºæœ€ä½³æ–¹æ¡ˆ
    if analyses:
        best_overall = max(analyses, key=lambda x: x['score'])
        best_segment = max([a for a in analyses if a['level_type'] == 'segment'], key=lambda x: x['score'], default=None)
        best_word = max([a for a in analyses if a['level_type'] == 'word'], key=lambda x: x['score'], default=None)
        
        print(f"\nğŸ¥‡ æœ€ä½³æ–¹æ¡ˆ:")
        print(f"  æ•´é«”æœ€ä½³: {best_overall['name']} ({best_overall['score']:.0f}/60)")
        if best_segment:
            print(f"  æ®µè½ç´šæœ€ä½³: {best_segment['name']} ({best_segment['score']:.0f}/60)")
        if best_word:
            print(f"  è©å½™ç´šæœ€ä½³: {best_word['name']} ({best_word['score']:.0f}/60)")
    
    # é‡å°ç”¨æˆ¶åŸå§‹å•é¡Œçš„åˆ†æ
    print(f"\nğŸ’¡ é‡å°ç”¨æˆ¶åŸå§‹å•é¡Œçš„è§£æ±ºæ–¹æ¡ˆ:")
    print(f"  åŸå§‹å•é¡Œ: Whisper-1 æ®µè½éé•· (19å­—ç¬¦)")
    
    # æ®µè½ç´šè¡¨ç¾
    segment_analyses = [a for a in analyses if a['level_type'] == 'segment']
    if segment_analyses:
        avg_segment_max = sum(a['max_length'] for a in segment_analyses) / len(segment_analyses)
        print(f"  æ®µè½ç´šå¹³å‡æœ€é•·: {avg_segment_max:.1f} å­—ç¬¦ ({'å•é¡Œæ›´åš´é‡' if avg_segment_max > 19 else 'æœ‰æ”¹å–„'})")
    
    # è©å½™ç´šè¡¨ç¾
    word_analyses = [a for a in analyses if a['level_type'] == 'word']
    if word_analyses:
        avg_word_max = sum(a['max_length'] for a in word_analyses) / len(word_analyses)
        print(f"  è©å½™ç´šå¹³å‡æœ€é•·: {avg_word_max:.1f} å­—ç¬¦ ({'å®Œç¾è§£æ±º' if avg_word_max <= 18 else 'å¤§å¹…æ”¹å–„'})")
    
    # æœ€çµ‚å»ºè­°
    print(f"\nğŸ¯ æœ€çµ‚å»ºè­°:")
    if best_word:
        print(f"  ğŸ† æ¨è–¦æ–¹æ¡ˆ: {best_word['name']}")
        print(f"  ğŸ“ æ–‡ä»¶ä½ç½®: {best_word['filepath']}")
        print(f"  âœ… è©•åˆ†: {best_word['score']:.0f}/60")
        print(f"  âœ… æœ€é•·æ®µè½: {best_word['max_length']} å­—ç¬¦")
        print(f"  âœ… å•é¡Œæ®µè½: {best_word['long_segments_count']} å€‹")
        
        if best_word['score'] >= 60:
            print(f"  ğŸ‰ å®Œç¾è§£æ±ºæ‚¨çš„æ®µè½éé•·å•é¡Œï¼")
    
    # æ–‡ä»¶ä½ç½®ç¸½çµ
    print(f"\nğŸ“ æ‰€æœ‰æ¸¬è©¦çµæœæ–‡ä»¶ä½ç½®:")
    for analysis in analyses:
        print(f"  - {analysis['filepath']} ({analysis['name']})")
    
    print(f"\nğŸ“‹ çµæœæ•¸æ“šæ–‡ä»¶:")
    result_files = [
        "elevenlabs_segment_real_result.json",
        "assemblyai_segment_real_result.json"
    ]
    for filepath in result_files:
        if os.path.exists(filepath):
            file_size = os.path.getsize(filepath)
            print(f"  - {filepath} ({file_size} bytes)")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” å®Œæ•´æ®µè½ç´š vs è©å½™ç´šæ¯”è¼ƒåˆ†æ")
    print("åŒ…å« ElevenLabs, AssemblyAI, Groq ä¸‰å€‹æœå‹™")
    print("=" * 80)
    
    # æª¢æŸ¥æ‰€æœ‰å¿…è¦æ–‡ä»¶
    required_files = [
        "elevenlabs_segment_real.srt",
        "assemblyai_segment_real.srt",
        "elevenlabs_precise_18chars.srt",
        "assemblyai_precise_18chars.srt",
        "final_groq_word_level.srt"
    ]
    
    existing_files = [f for f in required_files if os.path.exists(f)]
    print(f"ğŸ“‹ å¯ç”¨æ–‡ä»¶: {len(existing_files)}/{len(required_files)}")
    
    if len(existing_files) < 3:
        print("âš ï¸ å¯ç”¨æ–‡ä»¶è¼ƒå°‘ï¼Œä½†ä»å¯é€²è¡Œæ¯”è¼ƒ")
    
    # åŸ·è¡Œå®Œæ•´æ¯”è¼ƒ
    analyses = create_complete_comparison()
    
    if analyses:
        # é¡¯ç¤ºå•é¡Œæ®µè½æ¨£æœ¬
        show_problem_samples(analyses)
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        generate_final_comprehensive_report(analyses)
        
        print(f"\nâœ… å®Œæ•´æ®µè½ç´š vs è©å½™ç´šæ¯”è¼ƒåˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š æˆåŠŸåˆ†æäº† {len(analyses)} å€‹æ¸¬è©¦çµæœ")
    else:
        print(f"âŒ åˆ†æå¤±æ•—")
    
    return analyses

if __name__ == "__main__":
    main()
