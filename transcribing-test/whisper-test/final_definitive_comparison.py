#!/usr/bin/env python3
"""
æœ€çµ‚ç¢ºå®šæ€§æ¯”è¼ƒ - ä½¿ç”¨æ­£ç¢ºçš„ API Key
æ¸¬è©¦æ‰€æœ‰æœ€ä½³æ–¹æ¡ˆï¼ŒåŒ…å« Groq çš„è©å½™ç´šæ”¯æ´
"""

import os
from dotenv import load_dotenv
import time
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def create_srt_from_segments(segments):
    """å¾æ®µè½è³‡è¨Šå‰µå»º SRT"""
    srt_content = []
    
    for i, segment in enumerate(segments, 1):
        start_time = format_srt_time(segment.start)
        end_time = format_srt_time(segment.end)
        text = segment.text.strip()
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)

def create_custom_srt_from_words(words, max_chars=18):
    """ä½¿ç”¨è©å½™ç´šæ™‚é–“æˆ³è¨˜å‰µå»ºè‡ªå®šç¾© SRT"""
    if not words:
        return "ç„¡è©å½™è³‡è¨Š"
    
    subtitles = []
    current_subtitle = {
        'start': None,
        'end': None,
        'text': ''
    }
    
    for word_obj in words:
        word = word_obj.word if hasattr(word_obj, 'word') else str(word_obj)
        start_time = word_obj.start if hasattr(word_obj, 'start') else 0
        end_time = word_obj.end if hasattr(word_obj, 'end') else 0
        
        word = word.strip()
        if not word:
            continue
            
        # æ™ºèƒ½åˆ†æ®µ
        if (current_subtitle['start'] is None or 
            len(current_subtitle['text'] + word) > max_chars):
            
            if current_subtitle['text']:
                subtitles.append(current_subtitle.copy())
            
            current_subtitle = {
                'start': start_time,
                'end': end_time,
                'text': word
            }
        else:
            current_subtitle['text'] += word
            current_subtitle['end'] = end_time
    
    if current_subtitle['text']:
        subtitles.append(current_subtitle)
    
    # ç”Ÿæˆ SRT
    srt_content = []
    for i, subtitle in enumerate(subtitles, 1):
        start_time = format_srt_time(subtitle['start'])
        end_time = format_srt_time(subtitle['end'])
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(subtitle['text'])
        srt_content.append("")
    
    return "\n".join(srt_content)

def comprehensive_evaluation(srt_content, method_name):
    """å…¨é¢è©•ä¼° - æ®µè½é•·åº¦å’Œè½‰éŒ„å“è³ª"""
    print(f"\nğŸ¯ {method_name} - å…¨é¢è©•ä¼°")
    print("=" * 60)
    
    # è§£æ SRT
    lines = srt_content.strip().split('\n')
    segments = []
    full_text = ""
    
    i = 0
    while i < len(lines):
        if lines[i].strip().isdigit():
            if i + 2 < len(lines):
                segment_id = int(lines[i])
                time_line = lines[i + 1]
                text_lines = []
                i += 2
                while i < len(lines) and lines[i].strip():
                    text_lines.append(lines[i])
                    i += 1
                
                if text_lines:
                    text = ' '.join(text_lines).strip()
                    segments.append({
                        'id': segment_id,
                        'time': time_line,
                        'text': text,
                        'length': len(text)
                    })
                    full_text += text + " "
        i += 1
    
    if not segments:
        print("âŒ ç„¡æ³•è§£æ SRT")
        return None
    
    lengths = [seg['length'] for seg in segments]
    problem_segments = [seg for seg in segments if seg['length'] > 30]
    very_long_segments = [seg for seg in segments if seg['length'] > 40]
    
    print(f"ğŸ“Š æ®µè½çµ±è¨ˆ:")
    print(f"  ç¸½æ®µè½: {len(segments)}")
    print(f"  æœ€é•·æ®µè½: {max(lengths)} å­—ç¬¦")
    print(f"  å¹³å‡é•·åº¦: {sum(lengths)/len(lengths):.1f} å­—ç¬¦")
    print(f"  å•é¡Œæ®µè½ (>30å­—ç¬¦): {len(problem_segments)} å€‹")
    print(f"  åš´é‡å•é¡Œ (>40å­—ç¬¦): {len(very_long_segments)} å€‹")
    
    # è½‰éŒ„å“è³ªæª¢æŸ¥
    has_traditional = any(char in full_text for char in ['å°ç©é›»', 'è¯é›»', 'é€£æº–æœƒ', 'ç´æ–¯é”å…‹'])
    punctuation_count = full_text.count('ï¼Œ') + full_text.count('ã€‚') + full_text.count('ï¼') + full_text.count('ï¼Ÿ')
    
    print(f"\nğŸ“ è½‰éŒ„å“è³ª:")
    print(f"  èªè¨€: {'ç¹é«”ä¸­æ–‡ âœ…' if has_traditional else 'ç°¡é«”ä¸­æ–‡ âŒ'}")
    print(f"  æ¨™é»ç¬¦è™Ÿ: {punctuation_count} å€‹")
    
    # å°ˆæ¥­è¡“èªæª¢æŸ¥
    terms_correct = 0
    if 'å°ç©é›»' in full_text:
        terms_correct += 1
        print(f"  âœ… å°ç©é›» è­˜åˆ¥æ­£ç¢º")
    elif 'å°ç§¯ç”µ' in full_text:
        print(f"  âš ï¸ å°ç§¯ç”µ (ç°¡é«”)")
    
    if 'NVIDIA' in full_text or 'è¼é”' in full_text:
        terms_correct += 1
        print(f"  âœ… NVIDIA/è¼é” è­˜åˆ¥æ­£ç¢º")
    elif 'è¾‰è¾¾' in full_text:
        print(f"  âš ï¸ è¾‰è¾¾ (ç°¡é«”)")
    
    if 'ç´æ–¯é”å…‹' in full_text:
        terms_correct += 1
        print(f"  âœ… ç´æ–¯é”å…‹ è­˜åˆ¥æ­£ç¢º")
    elif 'é‚£æ–¯è¾¾å…‹' in full_text:
        print(f"  âš ï¸ é‚£æ–¯è¾¾å…‹ (ç°¡é«”)")
    
    if 'æ¯”ç‰¹å¹£' in full_text:
        terms_correct += 1
        print(f"  âœ… æ¯”ç‰¹å¹£ è­˜åˆ¥æ­£ç¢º")
    elif 'æ¯”ç‰¹å¸' in full_text:
        print(f"  âš ï¸ æ¯”ç‰¹å¸ (ç°¡é«”)")
    
    print(f"  å°ˆæ¥­è¡“èªæ­£ç¢ºç‡: {terms_correct}/4 å€‹")
    
    # ç¶œåˆè©•åˆ†
    segment_score = 0
    if max(lengths) <= 19:
        segment_score = 50  # èˆ‡ Whisper-1 åŸºæº–ç›¸ç•¶æˆ–æ›´å¥½
    elif max(lengths) <= 25:
        segment_score = 40
    elif max(lengths) <= 30:
        segment_score = 30
    elif len(very_long_segments) == 0:
        segment_score = 20
    else:
        segment_score = 10
    
    quality_score = 0
    if has_traditional:
        quality_score += 20
    quality_score += min(punctuation_count * 2, 15)
    quality_score += terms_correct * 3.75
    
    total_score = segment_score + quality_score
    
    print(f"\nğŸ“ˆ è©•åˆ†:")
    print(f"  æ®µè½æ§åˆ¶: {segment_score}/50")
    print(f"  è½‰éŒ„å“è³ª: {quality_score:.1f}/50") 
    print(f"  ç¸½è©•åˆ†: {total_score:.1f}/100")
    
    return {
        'total_score': total_score,
        'segment_score': segment_score,
        'quality_score': quality_score,
        'max_length': max(lengths),
        'problem_count': len(problem_segments),
        'very_long_count': len(very_long_segments),
        'has_traditional': has_traditional,
        'punctuation_count': punctuation_count,
        'terms_correct': terms_correct,
        'segments': segments
    }

def main():
    """æœ€çµ‚ç¢ºå®šæ€§æ¯”è¼ƒ"""
    print("ğŸ† æœ€çµ‚ç¢ºå®šæ€§æ¯”è¼ƒ - æ‰¾åˆ°çœŸæ­£æœ€ä½³è§£æ±ºæ–¹æ¡ˆ")
    print("=" * 80)
    
    # æ­£ç¢ºçš„ API è¨­å®š
    openai_api_key = os.getenv("OPENAI_API_KEY")
    groq_api_key = os.getenv("GROQ_API_KEY")
    
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” {audio_file}")
        return
    
    openai_client = OpenAI(api_key=openai_api_key)
    groq_client = OpenAI(
        api_key=groq_api_key,
        base_url="https://api.groq.com/openai/v1"
    )
    
    results = []
    
    # æœ€ä½³ Prompt
    best_prompt = "ç¾åœ‹ç™½å®®ç›´æ¥æŠŠé€²å£ä¸­åœ‹å•†å“çš„é—œç¨…ï¼Œå¾145%çˆ½æ‹‰åˆ°245%ã€‚ä¸­ç¾è²¿æ˜“æˆ°ç«ç›´æ¥åŠ å¤§é¦¬åŠ›ã€‚"
    
    # 1. Whisper-1 åŸºæº–
    print(f"\nğŸ“Š æ¸¬è©¦ 1: Whisper-1 åŸºæº–")
    try:
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="srt",
                language="zh"
            )
        
        with open("final_whisper1_baseline_correct.srt", "w", encoding="utf-8") as f:
            f.write(transcription)
        
        analysis = comprehensive_evaluation(transcription, "Whisper-1 åŸºæº–")
        results.append(('Whisper-1 åŸºæº–', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # 2. Whisper-1 + æœ€ä½³ Prompt
    print(f"\nğŸ“Š æ¸¬è©¦ 2: Whisper-1 + æœ€ä½³ Prompt")
    try:
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="srt",
                prompt=best_prompt,
                language="zh"
            )
        
        with open("final_whisper1_best_prompt_correct.srt", "w", encoding="utf-8") as f:
            f.write(transcription)
        
        analysis = comprehensive_evaluation(transcription, "Whisper-1 + æœ€ä½³Prompt")
        results.append(('Whisper-1 + æœ€ä½³Prompt', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # 3. Whisper-1 è©å½™ç´šè‡ªå®šç¾©
    print(f"\nğŸ“Š æ¸¬è©¦ 3: Whisper-1 è©å½™ç´šè‡ªå®šç¾©")
    try:
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],
                language="zh"
            )
        
        print(f"ğŸ“ ç²å¾— {len(transcription.words)} å€‹è©å½™æ™‚é–“æˆ³è¨˜")
        
        custom_srt = create_custom_srt_from_words(transcription.words, max_chars=18)
        
        with open("final_whisper1_word_level_correct.srt", "w", encoding="utf-8") as f:
            f.write(custom_srt)
        
        analysis = comprehensive_evaluation(custom_srt, "Whisper-1 è©å½™ç´šè‡ªå®šç¾©")
        results.append(('Whisper-1 è©å½™ç´šè‡ªå®šç¾©', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # 4. Groq è©å½™ç´šè‡ªå®šç¾© (å·²ç¢ºèªæ”¯æ´)
    print(f"\nğŸ“Š æ¸¬è©¦ 4: Groq è©å½™ç´šè‡ªå®šç¾©")
    try:
        with open(audio_file, "rb") as f:
            transcription = groq_client.audio.transcriptions.create(
                model="whisper-large-v3",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],
                language="zh"
            )
        
        print(f"ğŸ“ ç²å¾— {len(transcription.words)} å€‹è©å½™æ™‚é–“æˆ³è¨˜")
        
        custom_srt = create_custom_srt_from_words(transcription.words, max_chars=18)
        
        with open("final_groq_word_level.srt", "w", encoding="utf-8") as f:
            f.write(custom_srt)
        
        analysis = comprehensive_evaluation(custom_srt, "Groq è©å½™ç´šè‡ªå®šç¾©")
        results.append(('Groq è©å½™ç´šè‡ªå®šç¾©', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # 5. Groq + æœ€ä½³ Prompt + è©å½™ç´š
    print(f"\nğŸ“Š æ¸¬è©¦ 5: Groq + æœ€ä½³ Prompt + è©å½™ç´š")
    try:
        with open(audio_file, "rb") as f:
            transcription = groq_client.audio.transcriptions.create(
                model="whisper-large-v3",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],
                prompt=best_prompt,
                language="zh"
            )
        
        print(f"ğŸ“ ç²å¾— {len(transcription.words)} å€‹è©å½™æ™‚é–“æˆ³è¨˜")
        
        custom_srt = create_custom_srt_from_words(transcription.words, max_chars=18)
        
        with open("final_groq_prompt_word_level.srt", "w", encoding="utf-8") as f:
            f.write(custom_srt)
        
        analysis = comprehensive_evaluation(custom_srt, "Groq + Prompt + è©å½™ç´š")
        results.append(('Groq + Prompt + è©å½™ç´š', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # æœ€çµ‚æ’åå’Œçµè«–
    print(f"\n" + "=" * 80)
    print(f"ğŸ† æœ€çµ‚ç¢ºå®šæ€§çµæœ - çœŸæ­£æ¯” Whisper-1 æ›´å¥½çš„æ–¹æ¡ˆ")
    print("=" * 80)
    
    if results:
        # æŒ‰ç¸½è©•åˆ†æ’åº
        results.sort(key=lambda x: x[1]['total_score'], reverse=True)
        
        print(f"ğŸ“Š æœ€çµ‚æ’å:")
        
        whisper1_baseline_score = None
        
        for i, (method, analysis) in enumerate(results, 1):
            print(f"\n  {i}. {method}")
            print(f"     ç¸½è©•åˆ†: {analysis['total_score']:.1f}/100")
            print(f"     æ®µè½æ§åˆ¶: {analysis['segment_score']}/50 (æœ€é•· {analysis['max_length']} å­—ç¬¦)")
            print(f"     è½‰éŒ„å“è³ª: {analysis['quality_score']:.1f}/50")
            print(f"     ç¹é«”ä¸­æ–‡: {'âœ…' if analysis['has_traditional'] else 'âŒ'}")
            print(f"     å°ˆæ¥­è¡“èª: {analysis['terms_correct']}/4")
            
            if method == 'Whisper-1 åŸºæº–':
                whisper1_baseline_score = analysis['total_score']
            elif whisper1_baseline_score:
                improvement = analysis['total_score'] - whisper1_baseline_score
                if improvement > 5:
                    print(f"     ğŸ‰ æ¯” Whisper-1 å¥½ {improvement:.1f} åˆ†ï¼")
                elif improvement > 0:
                    print(f"     âœ… æ¯” Whisper-1 ç•¥å¥½ (+{improvement:.1f})")
                else:
                    print(f"     âŒ ä¸å¦‚ Whisper-1 ({improvement:.1f})")
        
        # æœ€çµ‚æ¨è–¦
        winner = results[0]
        print(f"\nğŸ… æœ€çµ‚æœ€ä½³è§£æ±ºæ–¹æ¡ˆ: {winner[0]}")
        print(f"   ç¸½è©•åˆ†: {winner[1]['total_score']:.1f}/100")
        print(f"   æœ€é•·æ®µè½: {winner[1]['max_length']} å­—ç¬¦")
        print(f"   å•é¡Œæ®µè½: {winner[1]['problem_count']} å€‹")
        
        if winner[1]['total_score'] > (whisper1_baseline_score or 0):
            print(f"   ğŸ‰ ç¢ºå¯¦æ¯” Whisper-1 åŸºæº–æ›´å¥½ï¼")
        else:
            print(f"   âš ï¸ èˆ‡ Whisper-1 åŸºæº–ç›¸ç•¶æˆ–ç¨å·®")
    
    print(f"\nğŸ‰ æœ€çµ‚ç¢ºå®šæ€§æ¯”è¼ƒå®Œæˆï¼")
    return results

if __name__ == "__main__":
    main()
