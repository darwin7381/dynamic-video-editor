#!/usr/bin/env python3
"""
ä½¿ç”¨æ­£ç¢ºæ¨¡å‹ ID æ¸¬è©¦ ElevenLabs Scribe
"""

import os
from dotenv import load_dotenv
import requests
import json

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def create_srt_from_segments(segments):
    """å¾æ®µè½å‰µå»º SRT"""
    srt_content = []
    
    for i, segment in enumerate(segments, 1):
        start_time = format_srt_time(segment['start_time'])
        end_time = format_srt_time(segment['end_time'])
        text = segment['text'].strip()
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)

def analyze_elevenlabs_result(result, service_name):
    """åˆ†æ ElevenLabs çµæœ"""
    print(f"\nğŸ¯ {service_name} è©³ç´°åˆ†æ")
    print("=" * 60)
    
    # æª¢æŸ¥çµæœçµæ§‹
    print(f"ğŸ“Š çµæœçµæ§‹: {result.keys() if isinstance(result, dict) else type(result)}")
    
    # ç²å–è½‰éŒ„æ–‡å­—
    transcript_text = ""
    if 'transcript' in result:
        transcript_text = result['transcript']
    elif 'text' in result:
        transcript_text = result['text']
    else:
        print(f"âŒ æ‰¾ä¸åˆ°è½‰éŒ„æ–‡å­—")
        return None
    
    print(f"ğŸ“ è½‰éŒ„æ–‡å­—é•·åº¦: {len(transcript_text)} å­—ç¬¦")
    print(f"ğŸ“‹ è½‰éŒ„å…§å®¹: {transcript_text}")
    
    # æª¢æŸ¥è½‰éŒ„å“è³ª
    has_traditional = any(char in transcript_text for char in ['å°ç©é›»', 'è¯é›»', 'é€£æº–æœƒ', 'ç´æ–¯é”å…‹'])
    punctuation_count = transcript_text.count('ï¼Œ') + transcript_text.count('ã€‚') + transcript_text.count('ï¼') + transcript_text.count('ï¼Ÿ')
    
    terms_found = 0
    if 'å°ç©é›»' in transcript_text:
        terms_found += 1
        print(f"  âœ… å°ç©é›» è­˜åˆ¥æ­£ç¢º")
    if 'NVIDIA' in transcript_text or 'è¼é”' in transcript_text:
        terms_found += 1
        print(f"  âœ… NVIDIA/è¼é” è­˜åˆ¥æ­£ç¢º")
    if 'ç´æ–¯é”å…‹' in transcript_text:
        terms_found += 1
        print(f"  âœ… ç´æ–¯é”å…‹ è­˜åˆ¥æ­£ç¢º")
    if 'æ¯”ç‰¹å¹£' in transcript_text:
        terms_found += 1
        print(f"  âœ… æ¯”ç‰¹å¹£ è­˜åˆ¥æ­£ç¢º")
    
    print(f"\nğŸ“ è½‰éŒ„å“è³ª:")
    print(f"  èªè¨€: {'ç¹é«”ä¸­æ–‡ âœ…' if has_traditional else 'ç°¡é«”ä¸­æ–‡ âŒ'}")
    print(f"  æ¨™é»ç¬¦è™Ÿ: {punctuation_count} å€‹")
    print(f"  å°ˆæ¥­è¡“èª: {terms_found}/4 å€‹")
    
    # æª¢æŸ¥æ™‚é–“æˆ³è¨˜
    if 'segments' in result or 'chunks' in result:
        segments_key = 'segments' if 'segments' in result else 'chunks'
        segments = result[segments_key]
        print(f"ğŸ“Š æ™‚é–“æˆ³è¨˜æ®µè½: {len(segments)} å€‹")
        
        # å‰µå»º SRT
        srt_content = create_srt_from_segments(segments)
        
        with open("elevenlabs_scribe_final.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        print(f"ğŸ’¾ SRT å·²ä¿å­˜: elevenlabs_scribe_final.srt")
        
        # åˆ†ææ®µè½é•·åº¦
        segment_lengths = [len(seg['text']) for seg in segments]
        problem_count = sum(1 for length in segment_lengths if length > 30)
        
        print(f"\nğŸ“Š æ®µè½åˆ†æ:")
        print(f"  æœ€é•·æ®µè½: {max(segment_lengths)} å­—ç¬¦")
        print(f"  å¹³å‡é•·åº¦: {sum(segment_lengths)/len(segment_lengths):.1f} å­—ç¬¦")
        print(f"  å•é¡Œæ®µè½ (>30å­—ç¬¦): {problem_count} å€‹")
        
        # èˆ‡æœ€ä½³æ–¹æ¡ˆæ¯”è¼ƒ
        print(f"\nğŸ† èˆ‡ Groq æœ€ä½³æ–¹æ¡ˆæ¯”è¼ƒ (95.2åˆ†):")
        print(f"  ElevenLabs æœ€é•·æ®µè½: {max(segment_lengths)} vs 18 (æœ€ä½³)")
        print(f"  ElevenLabs å•é¡Œæ®µè½: {problem_count} vs 0 (æœ€ä½³)")
        
        # è¨ˆç®—è©•åˆ†
        segment_score = 50 if max(segment_lengths) <= 18 and problem_count == 0 else 40 if max(segment_lengths) <= 25 else 30
        quality_score = 0
        if has_traditional:
            quality_score += 20
        quality_score += min(punctuation_count * 2, 15)
        quality_score += terms_found * 3.75
        
        total_score = segment_score + quality_score
        print(f"  ElevenLabs ç¸½è©•åˆ†: {total_score:.1f}/100")
        
        if total_score > 95:
            print(f"  ğŸ‰ ElevenLabs æ¯”æœ€ä½³æ–¹æ¡ˆæ›´å¥½ï¼")
        else:
            print(f"  âš ï¸ ElevenLabs ä¸å¦‚æœ€ä½³æ–¹æ¡ˆ")
        
        return {
            'success': True,
            'transcript_text': transcript_text,
            'srt_content': srt_content,
            'total_score': total_score,
            'max_length': max(segment_lengths),
            'problem_count': problem_count
        }
    else:
        print(f"âŒ æ²’æœ‰æ™‚é–“æˆ³è¨˜è³‡è¨Š")
        return {
            'success': True,
            'transcript_text': transcript_text,
            'srt_content': None,
            'total_score': quality_score if 'quality_score' in locals() else 0
        }

def main():
    """æ¸¬è©¦ ElevenLabs Scribe æ­£ç¢ºæ¨¡å‹"""
    print("ğŸ¯ ElevenLabs Scribe æ­£ç¢ºæ¨¡å‹æ¸¬è©¦")
    print("=" * 80)
    
    elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY")
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” {audio_file}")
        return
    
    # æ¸¬è©¦å…©å€‹å¯ç”¨çš„æ¨¡å‹
    models_to_test = ["scribe_v1", "scribe_v1_experimental"]
    
    for model_id in models_to_test:
        print(f"\nğŸ“Š æ¸¬è©¦æ¨¡å‹: {model_id}")
        
        try:
            url = "https://api.elevenlabs.io/v1/speech-to-text"
            
            headers = {
                "xi-api-key": elevenlabs_api_key
            }
            
            with open(audio_file, 'rb') as f:
                files = {
                    "file": (audio_file, f, "audio/mpeg")
                }
                
                data = {
                    "model_id": model_id
                }
                
                print(f"ğŸ”„ æäº¤ {model_id} è½‰éŒ„...")
                response = requests.post(url, headers=headers, files=files, data=data, timeout=120)
            
            print(f"ğŸ“Š å›æ‡‰ç‹€æ…‹: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… {model_id} è½‰éŒ„æˆåŠŸ")
                
                # ä¿å­˜çµæœ
                filename = f"elevenlabs_{model_id}_result.json"
                with open(filename, "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {filename}")
                
                # åˆ†æçµæœ
                analysis = analyze_elevenlabs_result(result, f"ElevenLabs {model_id}")
                
                if analysis and analysis['success']:
                    print(f"ğŸ¯ {model_id} æœ€çµ‚è©•åˆ†: {analysis.get('total_score', 0):.1f}/100")
                
            else:
                print(f"âŒ {model_id} å¤±æ•—: {response.text}")
                
        except Exception as e:
            print(f"âŒ {model_id} æ¸¬è©¦å¤±æ•—: {str(e)}")
    
    print(f"\nğŸ‰ ElevenLabs æ‰€æœ‰æ¨¡å‹æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()
