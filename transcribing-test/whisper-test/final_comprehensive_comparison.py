#!/usr/bin/env python3
"""
æœ€çµ‚å…¨é¢æ¯”è¼ƒ - æ¸¬è©¦æ‰€æœ‰æœ€ä½³æ–¹æ¡ˆ
åŒ…å« Groq è©å½™ç´šæ”¯æ´æ¸¬è©¦
"""

import os
from dotenv import load_dotenv
import time
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def create_srt_from_segments(segments):
    """å¾æ®µè½è³‡è¨Šå‰µå»º SRT"""
    srt_content = []
    
    for i, segment in enumerate(segments, 1):
        start_time = format_srt_time(segment.start)
        end_time = format_srt_time(segment.end)
        text = segment.text.strip()
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)

def create_custom_srt_from_words(words, max_chars=18):
    """ä½¿ç”¨è©å½™ç´šæ™‚é–“æˆ³è¨˜å‰µå»ºè‡ªå®šç¾© SRT"""
    if not words:
        return "ç„¡è©å½™è³‡è¨Š"
    
    subtitles = []
    current_subtitle = {
        'start': None,
        'end': None,
        'text': ''
    }
    
    for word_obj in words:
        word = word_obj.word if hasattr(word_obj, 'word') else str(word_obj)
        start_time = word_obj.start if hasattr(word_obj, 'start') else 0
        end_time = word_obj.end if hasattr(word_obj, 'end') else 0
        
        word = word.strip()
        if not word:
            continue
            
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é–‹å§‹æ–°æ®µè½
        if (current_subtitle['start'] is None or 
            len(current_subtitle['text'] + word) > max_chars):
            
            # ä¿å­˜ç•¶å‰æ®µè½
            if current_subtitle['text']:
                subtitles.append(current_subtitle.copy())
            
            # é–‹å§‹æ–°æ®µè½
            current_subtitle = {
                'start': start_time,
                'end': end_time,
                'text': word
            }
        else:
            # æ·»åŠ åˆ°ç•¶å‰æ®µè½
            current_subtitle['text'] += word
            current_subtitle['end'] = end_time
    
    # æ·»åŠ æœ€å¾Œä¸€å€‹æ®µè½
    if current_subtitle['text']:
        subtitles.append(current_subtitle)
    
    # ç”Ÿæˆ SRT
    srt_content = []
    for i, subtitle in enumerate(subtitles, 1):
        start_time = format_srt_time(subtitle['start'])
        end_time = format_srt_time(subtitle['end'])
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(subtitle['text'])
        srt_content.append("")
    
    return "\n".join(srt_content)

def final_quality_assessment(srt_content, method_name):
    """æœ€çµ‚å“è³ªè©•ä¼° - æ®µè½é•·åº¦ + è½‰éŒ„å“è³ª"""
    print(f"\nğŸ¯ {method_name} - æœ€çµ‚å“è³ªè©•ä¼°")
    print("=" * 60)
    
    # è§£æ SRT
    lines = srt_content.strip().split('\n')
    segments = []
    full_text = ""
    
    i = 0
    while i < len(lines):
        if lines[i].strip().isdigit():
            if i + 2 < len(lines):
                segment_id = int(lines[i])
                time_line = lines[i + 1]
                text_lines = []
                i += 2
                while i < len(lines) and lines[i].strip():
                    text_lines.append(lines[i])
                    i += 1
                
                if text_lines:
                    text = ' '.join(text_lines).strip()
                    segments.append({
                        'id': segment_id,
                        'time': time_line,
                        'text': text,
                        'length': len(text)
                    })
                    full_text += text + " "
        i += 1
    
    lengths = [seg['length'] for seg in segments]
    problem_segments = [seg for seg in segments if seg['length'] > 30]
    
    # æ®µè½å“è³ªè©•åˆ†
    segment_score = 0
    if max(lengths) <= 19:
        segment_score = 50  # èˆ‡ Whisper-1 åŸºæº–ç›¸ç•¶æˆ–æ›´å¥½
    elif max(lengths) <= 25:
        segment_score = 40
    elif max(lengths) <= 30:
        segment_score = 30
    elif len(problem_segments) <= 2:
        segment_score = 20
    else:
        segment_score = 10
    
    # è½‰éŒ„å“è³ªè©•åˆ†
    quality_score = 0
    
    # ç¹é«”ä¸­æ–‡ (20åˆ†)
    if any(char in full_text for char in ['å°ç©é›»', 'è¯é›»', 'é€£æº–æœƒ', 'ç´æ–¯é”å…‹']):
        quality_score += 20
    
    # æ¨™é»ç¬¦è™Ÿ (15åˆ†)
    punctuation_count = full_text.count('ï¼Œ') + full_text.count('ã€‚') + full_text.count('ï¼') + full_text.count('ï¼Ÿ')
    quality_score += min(punctuation_count * 2, 15)
    
    # å°ˆæ¥­è¡“èªè­˜åˆ¥ (15åˆ†)
    terms_found = 0
    if 'å°ç©é›»' in full_text:
        terms_found += 1
    if 'NVIDIA' in full_text or 'è¼é”' in full_text:
        terms_found += 1
    if 'ç´æ–¯é”å…‹' in full_text:
        terms_found += 1
    if 'æ¯”ç‰¹å¹£' in full_text:
        terms_found += 1
    
    quality_score += terms_found * 3.75  # æ¯å€‹è¡“èª3.75åˆ†
    
    total_score = segment_score + quality_score
    
    print(f"ğŸ“Š è©•ä¼°çµæœ:")
    print(f"  æ®µè½æ§åˆ¶è©•åˆ†: {segment_score}/50 (æœ€é•· {max(lengths)} å­—ç¬¦)")
    print(f"  è½‰éŒ„å“è³ªè©•åˆ†: {quality_score}/50")
    print(f"  ğŸ“ˆ ç¸½è©•åˆ†: {total_score}/100")
    
    # é¡¯ç¤ºé—œéµè³‡è¨Š
    print(f"\nğŸ“‹ é—œéµæŒ‡æ¨™:")
    print(f"  æœ€é•·æ®µè½: {max(lengths)} å­—ç¬¦")
    print(f"  å•é¡Œæ®µè½: {len(problem_segments)} å€‹")
    print(f"  ç¹é«”ä¸­æ–‡: {'âœ…' if quality_score >= 20 else 'âŒ'}")
    print(f"  æ¨™é»ç¬¦è™Ÿ: {punctuation_count} å€‹")
    print(f"  å°ˆæ¥­è¡“èª: {terms_found}/4 å€‹")
    
    return {
        'total_score': total_score,
        'segment_score': segment_score,
        'quality_score': quality_score,
        'max_length': max(lengths),
        'problem_count': len(problem_segments),
        'punctuation_count': punctuation_count,
        'terms_found': terms_found,
        'segments': segments
    }

def main():
    """æœ€çµ‚å…¨é¢æ¯”è¼ƒæ¸¬è©¦"""
    print("ğŸ† æœ€çµ‚å…¨é¢æ¯”è¼ƒ - æ‰¾åˆ°çœŸæ­£æœ€ä½³çš„è§£æ±ºæ–¹æ¡ˆ")
    print("=" * 80)
    
    # API è¨­å®š
    openai_api_key = os.getenv("OPENAI_API_KEY")
    groq_api_key = os.getenv("GROQ_API_KEY")
    
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” {audio_file}")
        return
    
    openai_client = OpenAI(api_key=openai_api_key)
    groq_client = OpenAI(
        api_key=groq_api_key,
        base_url="https://api.groq.com/openai/v1"
    )
    
    results = []
    
    # æœ€ä½³ Prompt (åŸºæ–¼å‰é¢çš„æ¸¬è©¦çµæœ)
    best_prompt = "ç¾åœ‹ç™½å®®ç›´æ¥æŠŠé€²å£ä¸­åœ‹å•†å“çš„é—œç¨…ï¼Œå¾145%çˆ½æ‹‰åˆ°245%ã€‚ä¸­ç¾è²¿æ˜“æˆ°ç«ç›´æ¥åŠ å¤§é¦¬åŠ›ã€‚"
    
    # 1. Whisper-1 åŸºæº–
    print(f"\nğŸ“Š æ¸¬è©¦ 1: Whisper-1 åŸºæº–")
    try:
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="srt",
                language="zh"
            )
        
        with open("final_whisper1_baseline.srt", "w", encoding="utf-8") as f:
            f.write(transcription)
        
        analysis = final_quality_assessment(transcription, "Whisper-1 åŸºæº–")
        results.append(('Whisper-1 åŸºæº–', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # 2. Whisper-1 + æœ€ä½³ Prompt
    print(f"\nğŸ“Š æ¸¬è©¦ 2: Whisper-1 + æœ€ä½³ Prompt")
    try:
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="srt",
                prompt=best_prompt,
                language="zh"
            )
        
        with open("final_whisper1_best_prompt.srt", "w", encoding="utf-8") as f:
            f.write(transcription)
        
        analysis = final_quality_assessment(transcription, "Whisper-1 + æœ€ä½³Prompt")
        results.append(('Whisper-1 + æœ€ä½³Prompt', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # 3. Whisper-1 è©å½™ç´šè‡ªå®šç¾©
    print(f"\nğŸ“Š æ¸¬è©¦ 3: Whisper-1 è©å½™ç´šè‡ªå®šç¾©")
    try:
        with open(audio_file, "rb") as f:
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],
                language="zh"
            )
        
        print(f"ğŸ“ ç²å¾— {len(transcription.words)} å€‹è©å½™æ™‚é–“æˆ³è¨˜")
        
        custom_srt = create_custom_srt_from_words(transcription.words, max_chars=18)
        
        with open("final_whisper1_word_level.srt", "w", encoding="utf-8") as f:
            f.write(custom_srt)
        
        analysis = final_quality_assessment(custom_srt, "Whisper-1 è©å½™ç´šè‡ªå®šç¾©")
        results.append(('Whisper-1 è©å½™ç´šè‡ªå®šç¾©', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # 4. æ¸¬è©¦ Groq æ˜¯å¦æ”¯æ´è©å½™ç´šæ™‚é–“æˆ³è¨˜
    print(f"\nğŸ“Š æ¸¬è©¦ 4: Groq è©å½™ç´šæ”¯æ´æª¢æŸ¥")
    try:
        with open(audio_file, "rb") as f:
            # å˜—è©¦ timestamp_granularities åƒæ•¸
            transcription = groq_client.audio.transcriptions.create(
                model="whisper-large-v3",
                file=f,
                response_format="verbose_json",
                timestamp_granularities=["segment", "word"],  # å˜—è©¦è©å½™ç´š
                language="zh"
            )
        
        print(f"âœ… Groq æ”¯æ´ timestamp_granularities åƒæ•¸")
        print(f"ğŸ“Š æ®µè½æ•¸: {len(transcription.segments) if hasattr(transcription, 'segments') else 0}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è©å½™ç´šæ™‚é–“æˆ³è¨˜
        if hasattr(transcription, 'words') and transcription.words:
            print(f"ğŸ‰ Groq æ”¯æ´è©å½™ç´šæ™‚é–“æˆ³è¨˜ï¼ç²å¾— {len(transcription.words)} å€‹è©å½™")
            
            # å‰µå»ºè©å½™ç´š SRT
            custom_srt = create_custom_srt_from_words(transcription.words, max_chars=18)
            
            with open("final_groq_word_level.srt", "w", encoding="utf-8") as f:
                f.write(custom_srt)
            
            analysis = final_quality_assessment(custom_srt, "Groq è©å½™ç´šè‡ªå®šç¾©")
            results.append(('Groq è©å½™ç´šè‡ªå®šç¾©', analysis))
            
        else:
            print(f"âŒ Groq ä¸æ”¯æ´è©å½™ç´šæ™‚é–“æˆ³è¨˜")
            
            # ä½¿ç”¨æ®µè½ç´šå‰µå»º SRT
            srt_content = create_srt_from_segments(transcription.segments)
            
            with open("final_groq_segment_level.srt", "w", encoding="utf-8") as f:
                f.write(srt_content)
            
            analysis = final_quality_assessment(srt_content, "Groq æ®µè½ç´š")
            results.append(('Groq æ®µè½ç´š', analysis))
        
    except Exception as e:
        print(f"âŒ Groq è©å½™ç´šæ¸¬è©¦å¤±æ•—: {str(e)}")
    
    # 5. Groq + æœ€ä½³ Prompt
    print(f"\nğŸ“Š æ¸¬è©¦ 5: Groq + æœ€ä½³ Prompt")
    try:
        with open(audio_file, "rb") as f:
            transcription = groq_client.audio.transcriptions.create(
                model="whisper-large-v3",
                file=f,
                response_format="verbose_json",
                prompt=best_prompt,
                language="zh"
            )
        
        srt_content = create_srt_from_segments(transcription.segments)
        
        with open("final_groq_best_prompt.srt", "w", encoding="utf-8") as f:
            f.write(srt_content)
        
        analysis = final_quality_assessment(srt_content, "Groq + æœ€ä½³Prompt")
        results.append(('Groq + æœ€ä½³Prompt', analysis))
        
    except Exception as e:
        print(f"âŒ å¤±æ•—: {str(e)}")
    
    # æœ€çµ‚æ’å
    print(f"\n" + "=" * 80)
    print(f"ğŸ† æœ€çµ‚å…¨é¢æ¯”è¼ƒçµæœ")
    print("=" * 80)
    
    if results:
        # æŒ‰ç¸½è©•åˆ†æ’åº
        results.sort(key=lambda x: x[1]['total_score'], reverse=True)
        
        print(f"ğŸ“Š æœ€çµ‚æ’å (æ®µè½æ§åˆ¶ + è½‰éŒ„å“è³ª):")
        
        for i, (method, analysis) in enumerate(results, 1):
            print(f"\n  {i}. {method}")
            print(f"     ç¸½è©•åˆ†: {analysis['total_score']}/100")
            print(f"     æ®µè½æ§åˆ¶: {analysis['segment_score']}/50 (æœ€é•· {analysis['max_length']} å­—ç¬¦)")
            print(f"     è½‰éŒ„å“è³ª: {analysis['quality_score']}/50")
            print(f"     å•é¡Œæ®µè½: {analysis['problem_count']} å€‹")
            print(f"     å°ˆæ¥­è¡“èª: {analysis['terms_found']}/4 å€‹")
        
        # æœ€ä½³è§£æ±ºæ–¹æ¡ˆ
        winner = results[0]
        print(f"\nğŸ… æœ€çµ‚æœ€ä½³è§£æ±ºæ–¹æ¡ˆ: {winner[0]}")
        print(f"   ç¸½è©•åˆ†: {winner[1]['total_score']}/100")
        print(f"   ğŸ¯ é€™æ˜¯è§£æ±ºæ‚¨å•é¡Œçš„æœ€ä½³æ–¹æ¡ˆï¼")
        
        # èˆ‡ Whisper-1 åŸºæº–æ¯”è¼ƒ
        whisper1_baseline = next((r for r in results if r[0] == 'Whisper-1 åŸºæº–'), None)
        if whisper1_baseline and winner[0] != 'Whisper-1 åŸºæº–':
            improvement = winner[1]['total_score'] - whisper1_baseline[1]['total_score']
            print(f"   æ¯” Whisper-1 åŸºæº–æå‡: {improvement:.1f} åˆ†")
    
    print(f"\nğŸ‰ æœ€çµ‚å…¨é¢æ¯”è¼ƒå®Œæˆï¼")
    return results

if __name__ == "__main__":
    main()
