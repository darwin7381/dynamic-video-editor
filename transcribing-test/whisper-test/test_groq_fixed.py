#!/usr/bin/env python3
"""
ä¿®å¾©å¾Œçš„ Groq Whisper Large v3 æ¸¬è©¦
æ­£ç¢ºè™•ç†æ™‚é–“æˆ³è¨˜è³‡è¨Š
"""

import os
from dotenv import load_dotenv
import time
import json
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def create_srt_from_groq_segments(segments):
    """å¾ Groq çš„æ®µè½è³‡è¨Šå‰µå»º SRT"""
    srt_content = []
    
    for i, segment in enumerate(segments, 1):
        start_time = format_srt_time(segment.start)
        end_time = format_srt_time(segment.end)
        text = segment.text.strip()
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")
    
    return "\n".join(srt_content)

def format_srt_time(seconds):
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def analyze_srt_quality(srt_content):
    """åˆ†æ SRT å“è³ª"""
    lines = srt_content.strip().split('\n')
    segments = []
    current_text = ""
    
    for line in lines:
        if line.strip().isdigit():
            if current_text:
                segments.append(current_text.strip())
            current_text = ""
        elif "-->" not in line and line.strip():
            current_text += line + " "
    
    if current_text:
        segments.append(current_text.strip())
    
    if segments:
        segment_lengths = [len(seg) for seg in segments]
        return {
            'segment_count': len(segments),
            'avg_length': sum(segment_lengths) / len(segment_lengths),
            'max_length': max(segment_lengths),
            'min_length': min(segment_lengths)
        }
    return None

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    groq_api_key = os.getenv("GROQ_API_KEY")
    audio_file = "test_audio.mp3"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°éŸ³æª” {audio_file}")
        return
    
    # åˆå§‹åŒ– Groq å®¢æˆ¶ç«¯
    groq_client = OpenAI(
        api_key=groq_api_key,
        base_url="https://api.groq.com/openai/v1"
    )
    
    print("ğŸš€ Groq Whisper Large v3 å®Œæ•´æ¸¬è©¦")
    print("=" * 60)
    
    try:
        start_time = time.time()
        
        with open(audio_file, "rb") as f:
            transcription = groq_client.audio.transcriptions.create(
                model="whisper-large-v3",
                file=f,
                response_format="verbose_json",
                language="zh"
            )
        
        processing_time = time.time() - start_time
        
        print(f"âœ… æˆåŠŸ - è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
        print(f"ğŸŒ æª¢æ¸¬èªè¨€: {transcription.language}")
        print(f"â±ï¸ éŸ³æª”æ™‚é•·: {transcription.duration} ç§’")
        print(f"ğŸ“ è½‰éŒ„æ–‡å­—é•·åº¦: {len(transcription.text)} å­—ç¬¦")
        
        # æª¢æŸ¥æ®µè½è³‡è¨Š
        if transcription.segments:
            segments = transcription.segments
            print(f"ğŸ“Š æ®µè½æ•¸: {len(segments)}")
            
            print(f"\nğŸ” æ®µè½è³‡è¨Šåˆ†æ:")
            segment_lengths = [len(seg.text) for seg in segments]
            avg_length = sum(segment_lengths) / len(segment_lengths)
            max_length = max(segment_lengths)
            min_length = min(segment_lengths)
            
            print(f"  å¹³å‡æ®µè½é•·åº¦: {avg_length:.1f} å­—ç¬¦")
            print(f"  æœ€é•·æ®µè½: {max_length} å­—ç¬¦")
            print(f"  æœ€çŸ­æ®µè½: {min_length} å­—ç¬¦")
            
            print(f"\nğŸ“‹ å‰ 5 å€‹æ®µè½:")
            for i, seg in enumerate(segments[:5]):
                duration = seg.end - seg.start
                print(f"  {i+1}. [{seg.start:.2f}-{seg.end:.2f}] ({duration:.2f}s) {seg.text}")
            
            # å‰µå»º SRT
            print(f"\nğŸ¯ å‰µå»º SRT å­—å¹•æ–‡ä»¶...")
            srt_content = create_srt_from_groq_segments(segments)
            
            # ä¿å­˜ SRT
            with open("groq_whisper_large_v3_generated.srt", "w", encoding="utf-8") as f:
                f.write(srt_content)
            
            print(f"âœ… SRT å·²ä¿å­˜: groq_whisper_large_v3_generated.srt")
            
            # åˆ†æ SRT å“è³ª
            srt_quality = analyze_srt_quality(srt_content)
            if srt_quality:
                print(f"\nğŸ“Š SRT å“è³ªåˆ†æ:")
                print(f"  æ®µè½æ•¸: {srt_quality['segment_count']}")
                print(f"  å¹³å‡é•·åº¦: {srt_quality['avg_length']:.1f} å­—ç¬¦")
                print(f"  æœ€é•·æ®µè½: {srt_quality['max_length']} å­—ç¬¦")
                print(f"  æœ€çŸ­æ®µè½: {srt_quality['min_length']} å­—ç¬¦")
            
            # é¡¯ç¤º SRT é è¦½
            print(f"\nğŸ“„ SRT é è¦½:")
            preview_lines = srt_content.split('\n')[:20]
            for line in preview_lines:
                print(f"  {line}")
            if len(srt_content.split('\n')) > 20:
                print(f"  ...")
        
        # æª¢æŸ¥è©å½™è³‡è¨Š
        if transcription.words:
            print(f"ğŸ“ è©å½™ç´šæ™‚é–“æˆ³è¨˜: {len(transcription.words)} å€‹è©å½™")
        else:
            print(f"âŒ æ²’æœ‰è©å½™ç´šæ™‚é–“æˆ³è¨˜")
        
        # ä¿å­˜å®Œæ•´çš„è½‰éŒ„è³‡è¨Š
        transcription_dict = {
            'text': transcription.text,
            'language': transcription.language,
            'duration': transcription.duration,
            'segments': [
                {
                    'id': seg.id,
                    'start': seg.start,
                    'end': seg.end,
                    'text': seg.text,
                    'avg_logprob': seg.avg_logprob,
                    'compression_ratio': seg.compression_ratio,
                    'no_speech_prob': seg.no_speech_prob
                } for seg in transcription.segments
            ] if transcription.segments else [],
            'words': transcription.words  # é€™å€‹å¯èƒ½æ˜¯ None
        }
        
        with open("groq_transcription_complete.json", "w", encoding="utf-8") as f:
            json.dump(transcription_dict, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ å®Œæ•´è½‰éŒ„è³‡è¨Šå·²ä¿å­˜: groq_transcription_complete.json")
        
        return {
            'success': True,
            'processing_time': processing_time,
            'has_segments': bool(transcription.segments),
            'has_words': bool(transcription.words),
            'segment_count': len(transcription.segments) if transcription.segments else 0,
            'word_count': len(transcription.words) if transcription.words else 0,
            'srt_quality': srt_quality
        }
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

if __name__ == "__main__":
    result = main()
    
    print(f"\n" + "=" * 60)
    print(f"ğŸ“Š æœ€çµ‚çµæœç¸½çµ")
    print(f"=" * 60)
    
    if result['success']:
        print(f"âœ… æ¸¬è©¦æˆåŠŸ")
        print(f"â±ï¸ è™•ç†æ™‚é–“: {result['processing_time']:.2f} ç§’")
        print(f"ğŸ“Š æ®µè½ç´šæ™‚é–“æˆ³è¨˜: {'æ”¯æ´' if result['has_segments'] else 'ä¸æ”¯æ´'} ({result['segment_count']} å€‹)")
        print(f"ğŸ“ è©å½™ç´šæ™‚é–“æˆ³è¨˜: {'æ”¯æ´' if result['has_words'] else 'ä¸æ”¯æ´'} ({result['word_count']} å€‹)")
        
        if result['srt_quality']:
            quality = result['srt_quality']
            print(f"\nğŸ¯ SRT å“è³ª:")
            print(f"  æœ€é•·æ®µè½: {quality['max_length']} å­—ç¬¦")
            print(f"  å¹³å‡æ®µè½: {quality['avg_length']:.1f} å­—ç¬¦")
        
        if result['has_segments']:
            print(f"\nğŸ‰ çµè«–: Groq Whisper Large v3 æ”¯æ´æ®µè½ç´šæ™‚é–“æˆ³è¨˜ï¼Œå¯ä»¥ç”Ÿæˆ SRTï¼")
        else:
            print(f"\nğŸ˜ çµè«–: Groq Whisper Large v3 ä¸æ”¯æ´æ™‚é–“æˆ³è¨˜")
    else:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {result['error']}")
    
    print(f"\nğŸš€ Groq Whisper Large v3 é€Ÿåº¦å„ªå‹¢: ç´„ {result['processing_time']:.2f} ç§’ (æ¯” OpenAI whisper-1 å¿«ç´„ 70%)")
